# streamlit run a20_00_responses_skeleton.py --server.port=8501
# æ”¹ä¿®ç‰ˆ: æ–°ã—ã„ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ãŸ Responses API ã‚µãƒ³ãƒ—ãƒ«
# ==================================================
# åŸºæœ¬æ©Ÿèƒ½ã®ãƒ‡ãƒ¢: responses.create ã¨ responses.parse
# å·¦ãƒšã‚¤ãƒ³ã«è©³ç´°æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ãƒªãƒƒãƒãªUI
# ==================================================

import os
import sys
from typing import List, Dict, Any, Optional
from pathlib import Path

import streamlit as st
from pydantic import BaseModel, Field

# æ”¹ä¿®ã•ã‚ŒãŸãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from helper_st import (
        UIHelper, MessageManagerUI, ResponseProcessorUI,
        SessionStateManager, error_handler_ui, timer_ui,
        init_page, select_model
    )
    from helper_api import (
        config, logger, TokenManager, OpenAIClient,
        EasyInputMessageParam, ResponseInputTextParam
    )
except ImportError as e:
    st.error(f"ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.stop()


# ==================================================
# Pydantic ãƒ¢ãƒ‡ãƒ«å®šç¾©
# ==================================================
class UserInfo(BaseModel):
    name: str = Field(..., description="ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
    age: int = Field(..., ge=0, le=150, description="å¹´é½¢")
    city: str = Field(..., description="å±…ä½éƒ½å¸‚")


class People(BaseModel):
    users: List[UserInfo] = Field(..., description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§")
    total_count: int = Field(..., description="ç·äººæ•°")


# ==================================================
# æƒ…å ±ãƒ‘ãƒãƒ«è¡¨ç¤ºé–¢æ•°
# ==================================================
class InfoPanelManager:
    """å·¦ãƒšã‚¤ãƒ³ã®æƒ…å ±ãƒ‘ãƒãƒ«ç®¡ç†"""

    @staticmethod
    def show_model_info(selected_model: str):
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãƒ‘ãƒãƒ«"""
        with st.sidebar.expander("ğŸ¤– ãƒ¢ãƒ‡ãƒ«æƒ…å ±", expanded=True):
            # åŸºæœ¬æƒ…å ±
            limits = TokenManager.get_model_limits(selected_model)
            pricing = config.get("model_pricing", {}).get(selected_model, {})

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
            col1, col2 = st.columns(2)
            with col1:
                st.metric("æœ€å¤§å…¥åŠ›", f"{limits['max_tokens']:,}")
                st.metric("æœ€å¤§å‡ºåŠ›", f"{limits['max_output']:,}")
            with col2:
                if pricing:
                    st.metric("å…¥åŠ›æ–™é‡‘", f"${pricing.get('input', 0):.5f}/1K")
                    st.metric("å‡ºåŠ›æ–™é‡‘", f"${pricing.get('output', 0):.5f}/1K")

            # ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ†ã‚´ãƒª
            categories = config.get("models.categories", {})
            model_category = "ä¸æ˜"
            for category, models in categories.items():
                if selected_model in models:
                    model_category = category
                    break

            st.info(f"ğŸ“‚ ã‚«ãƒ†ã‚´ãƒª: {model_category}")

            # ãƒ¢ãƒ‡ãƒ«ç‰¹æ€§
            if "reasoning" in model_category:
                st.success("ğŸ§  æ¨è«–ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ« - è¤‡é›‘ãªå•é¡Œè§£æ±ºã«æœ€é©")
            elif "audio" in selected_model:
                st.success("ğŸµ éŸ³å£°å¯¾å¿œãƒ¢ãƒ‡ãƒ« - éŸ³å£°å…¥å‡ºåŠ›ãŒå¯èƒ½")
            elif "vision" in selected_model or "gpt-4o" in selected_model:
                st.success("ğŸ‘ï¸ è¦–è¦šå¯¾å¿œãƒ¢ãƒ‡ãƒ« - ç”»åƒç†è§£ãŒå¯èƒ½")

    @staticmethod
    def show_session_info():
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ãƒ‘ãƒãƒ«"""
        with st.sidebar.expander("ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±", expanded=False):
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ
            session_data = {}
            for key, value in st.session_state.items():
                if not key.startswith('_'):
                    session_data[key] = str(type(value).__name__)

            st.write("**ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°**")
            for key, value_type in list(session_data.items())[:5]:  # æœ€åˆã®5å€‹ã®ã¿è¡¨ç¤º
                st.write(f"- `{key}`: {value_type}")

            if len(session_data) > 5:
                st.write(f"... ä»– {len(session_data) - 5} å€‹")

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆç°¡æ˜“ï¼‰
            import sys
            session_size = sys.getsizeof(st.session_state)
            st.metric("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚º", f"{session_size:,} bytes")

    @staticmethod
    def show_performance_info():
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ãƒ‘ãƒãƒ«"""
        metrics = SessionStateManager.get_performance_metrics()
        if not metrics:
            return

        with st.sidebar.expander("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", expanded=False):
            recent_metrics = metrics[-5:]  # æœ€è¿‘ã®5å›

            if recent_metrics:
                avg_time = sum(m['execution_time'] for m in recent_metrics) / len(recent_metrics)
                max_time = max(m['execution_time'] for m in recent_metrics)
                min_time = min(m['execution_time'] for m in recent_metrics)

                col1, col2 = st.columns(2)
                with col1:
                    st.metric("å¹³å‡", f"{avg_time:.2f}s")
                    st.metric("æœ€å¤§", f"{max_time:.2f}s")
                with col2:
                    st.metric("æœ€å°", f"{min_time:.2f}s")
                    st.metric("å®Ÿè¡Œå›æ•°", len(metrics))

                # æœ€æ–°ã®å®Ÿè¡Œæ™‚é–“
                if metrics:
                    latest = recent_metrics[-1]
                    st.write(f"**æœ€æ–°å®Ÿè¡Œ**: {latest['function']} ({latest['execution_time']:.2f}s)")

    @staticmethod
    def show_cost_calculator(selected_model: str):
        """æ–™é‡‘è¨ˆç®—ãƒ‘ãƒãƒ«"""
        with st.sidebar.expander("ğŸ’° æ–™é‡‘è¨ˆç®—", expanded=False):
            pricing = config.get("model_pricing", {}).get(selected_model)
            if not pricing:
                st.warning("æ–™é‡‘æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return

            # å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
            input_tokens = st.number_input(
                "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°",
                min_value=0,
                value=1000,
                step=100,
                help="äºˆæƒ³ã•ã‚Œã‚‹å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°"
            )
            output_tokens = st.number_input(
                "å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°",
                min_value=0,
                value=500,
                step=100,
                help="äºˆæƒ³ã•ã‚Œã‚‹å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°"
            )

            # æ–™é‡‘è¨ˆç®—
            if st.button("ğŸ’° æ–™é‡‘è¨ˆç®—", use_container_width=True):
                cost = TokenManager.estimate_cost(input_tokens, output_tokens, selected_model)

                # è©³ç´°è¡¨ç¤º
                input_cost = (input_tokens / 1000) * pricing["input"]
                output_cost = (output_tokens / 1000) * pricing["output"]

                st.success(f"**ç·ã‚³ã‚¹ãƒˆ**: ${cost:.6f}")
                st.write(f"- å…¥åŠ›: ${input_cost:.6f}")
                st.write(f"- å‡ºåŠ›: ${output_cost:.6f}")

                # æœˆé–“ã‚³ã‚¹ãƒˆæ¨å®š
                daily_calls = st.slider("1æ—¥ã®å‘¼ã³å‡ºã—å›æ•°", 1, 1000, 100)
                monthly_cost = cost * daily_calls * 30
                st.info(f"**æœˆé–“æ¨å®š**: ${monthly_cost:.2f}")

    @staticmethod
    def show_debug_panel():
        """ãƒ‡ãƒãƒƒã‚°ãƒ‘ãƒãƒ«"""
        if not config.get("experimental.debug_mode", False):
            return

        with st.sidebar.expander("ğŸ› ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=False):
            # è¨­å®šæƒ…å ±
            st.write("**ã‚¢ã‚¯ãƒ†ã‚£ãƒ–è¨­å®š**")
            debug_config = {
                "default_model"         : config.get("models.default"),
                "cache_enabled"         : config.get("cache.enabled"),
                "debug_mode"            : config.get("experimental.debug_mode"),
                "performance_monitoring": config.get("experimental.performance_monitoring")
            }

            for key, value in debug_config.items():
                st.write(f"- {key}: `{value}`")

            # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«
            current_level = config.get("logging.level", "INFO")
            new_level = st.selectbox(
                "ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«",
                ["DEBUG", "INFO", "WARNING", "ERROR"],
                index=["DEBUG", "INFO", "WARNING", "ERROR"].index(current_level)
            )
            if new_level != current_level:
                config.set("logging.level", new_level)
                logger.setLevel(getattr(logger, new_level))

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æƒ…å ±
            from helper_api import cache
            st.write(f"**ã‚­ãƒ£ãƒƒã‚·ãƒ¥**: {cache.size()} ã‚¨ãƒ³ãƒˆãƒª")
            if st.button("ğŸ—‘ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"):
                cache.clear()
                st.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")


# ==================================================
# ãƒ‡ãƒ¢ã‚¯ãƒ©ã‚¹å®šç¾©
# ==================================================
class ResponsesSkeletonDemo:
    """Responses APIåŸºæœ¬ãƒ‡ãƒ¢ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.demo_name = "responses_skeleton"
        self.message_manager = MessageManagerUI(f"messages_{self.demo_name}")
        SessionStateManager.init_session_state()

    def setup_sidebar(self, selected_model: str):
        """å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š"""
        st.sidebar.title("ğŸ“‹ æƒ…å ±ãƒ‘ãƒãƒ«")

        # å„æƒ…å ±ãƒ‘ãƒãƒ«ã‚’è¡¨ç¤º
        InfoPanelManager.show_model_info(selected_model)
        InfoPanelManager.show_session_info()
        InfoPanelManager.show_performance_info()
        InfoPanelManager.show_cost_calculator(selected_model)
        InfoPanelManager.show_debug_panel()

        # è¨­å®šãƒ‘ãƒãƒ«
        UIHelper.show_settings_panel()

    @error_handler_ui
    @timer_ui
    def responses_create_demo(self, selected_model: str):
        """responses.create ãƒ‡ãƒ¢"""
        st.subheader("ğŸ¯ responses.create ãƒ‡ãƒ¢")

        # èª¬æ˜
        st.info("""
        **responses.create** ã¯æœ€ã‚‚åŸºæœ¬çš„ãªAPIå‘¼ã³å‡ºã—ã§ã™ã€‚
        ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ãŒè‡ªç„¶è¨€èªã§å¿œç­”ã—ã¾ã™ã€‚
        """)

        # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
        user_input, submitted = UIHelper.create_input_form(
            key="create_form",
            label="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            submit_label="ğŸš€ é€ä¿¡",
            placeholder="ä¾‹: OpenAIã®Responses APIã«ã¤ã„ã¦æ•™ãˆã¦",
            help="ä½•ã§ã‚‚æ°—è»½ã«è³ªå•ã—ã¦ãã ã•ã„"
        )

        if submitted and user_input:
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨çŠ¶æ…‹è¡¨ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()

            try:
                # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãƒã‚§ãƒƒã‚¯
                token_count = TokenManager.count_tokens(user_input, selected_model)
                limits = TokenManager.get_model_limits(selected_model)

                if token_count > limits['max_tokens'] * 0.8:
                    st.warning(f"âš ï¸ å…¥åŠ›ãŒé•·ã™ãã¾ã™ ({token_count:,} ãƒˆãƒ¼ã‚¯ãƒ³)")
                    return

                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æº–å‚™
                status_text.text("ğŸ“ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æº–å‚™ä¸­...")
                progress_bar.progress(20)

                messages = self.message_manager.get_default_messages()
                messages.append(EasyInputMessageParam(role="user", content=user_input))

                # APIå‘¼ã³å‡ºã—
                status_text.text("ğŸ¤– AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­...")
                progress_bar.progress(50)

                client = OpenAIClient()
                response = client.create_response(messages, model=selected_model)

                # çµæœè¡¨ç¤º
                status_text.text("âœ… å®Œäº†!")
                progress_bar.progress(100)

                # å›ç­”è¡¨ç¤º
                ResponseProcessorUI.display_response(response, show_details=True)

                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã«è¿½åŠ 
                self.message_manager.add_message("user", user_input)
                texts = ResponseProcessorUI.extract_text(response)
                if texts:
                    self.message_manager.add_message("assistant", texts[0])

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                logger.error(f"responses.create error: {e}")
            finally:
                progress_bar.empty()
                status_text.empty()

    @error_handler_ui
    @timer_ui
    def responses_parse_demo(self, selected_model: str):
        """responses.parse ãƒ‡ãƒ¢"""
        st.subheader("ğŸ¯ responses.parse ãƒ‡ãƒ¢")

        # èª¬æ˜
        st.info("""
        **responses.parse** ã¯æ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ›ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
        Pydanticãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦JSONã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ãŸå›ç­”ã‚’å–å¾—ã§ãã¾ã™ã€‚
        """)

        # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
        sample_text = config.get("samples.prompts.event_example",
                                 "ç§ã®åå‰ã¯ç”°ä¸­å¤ªéƒã€30æ­³ã€æ±äº¬åœ¨ä½ã§ã™ã€‚ç§ã®å‹äººã¯éˆ´æœ¨å¥å¤ªã€28æ­³ã€å¤§é˜ªåœ¨ä½ã§ã™ã€‚")

        # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
        user_input, submitted = UIHelper.create_input_form(
            key="parse_form",
            label="äººç‰©æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            submit_label="ğŸ”„ æ§‹é€ åŒ–",
            value=sample_text,
            help="åå‰ã€å¹´é½¢ã€ä½æ‰€ãŒå«ã¾ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›"
        )

        # ã‚¹ã‚­ãƒ¼ãƒè¡¨ç¤º
        with st.expander("ğŸ“‹ å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒ", expanded=False):
            st.code("""
class UserInfo(BaseModel):
    name: str = Field(..., description="ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
    age: int = Field(..., ge=0, le=150, description="å¹´é½¢")
    city: str = Field(..., description="å±…ä½éƒ½å¸‚")

class People(BaseModel):
    users: List[UserInfo] = Field(..., description="ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§")
    total_count: int = Field(..., description="ç·äººæ•°")
            """, language="python")

        if submitted and user_input:
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨çŠ¶æ…‹è¡¨ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()

            try:
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æº–å‚™
                status_text.text("ğŸ“ æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æº–å‚™ä¸­...")
                progress_bar.progress(25)

                messages = [
                    EasyInputMessageParam(
                        role="developer",
                        content="ã‚ãªãŸã¯æƒ…å ±æŠ½å‡ºã®å°‚é–€å®¶ã§ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰äººç‰©æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚"
                    ),
                    EasyInputMessageParam(
                        role="user",
                        content=[ResponseInputTextParam(type="input_text", text=user_input)]
                    )
                ]

                # APIå‘¼ã³å‡ºã—
                status_text.text("ğŸ”„ æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
                progress_bar.progress(70)

                client = OpenAIClient()
                response = client.client.responses.parse(
                    model=selected_model,
                    input=messages,
                    text_format=People
                )

                # çµæœå‡¦ç†
                status_text.text("âœ… æ§‹é€ åŒ–å®Œäº†!")
                progress_bar.progress(100)

                # çµæœè¡¨ç¤º
                if hasattr(response, 'output_parsed'):
                    people: People = response.output_parsed

                    st.success(f"ğŸ‰ {people.total_count}äººã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¾ã—ãŸ!")

                    # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
                    col1, col2 = st.columns([2, 1])

                    with col1:
                        st.subheader("ğŸ‘¥ æŠ½å‡ºã•ã‚ŒãŸäººç‰©æƒ…å ±")
                        for i, person in enumerate(people.users, 1):
                            with st.container():
                                st.write(f"**Person {i}**")
                                person_col1, person_col2, person_col3 = st.columns(3)
                                with person_col1:
                                    st.metric("åå‰", person.name)
                                with person_col2:
                                    st.metric("å¹´é½¢", f"{person.age}æ­³")
                                with person_col3:
                                    st.metric("å±…ä½åœ°", person.city)
                                st.divider()

                    with col2:
                        st.subheader("ğŸ“Š JSONå‡ºåŠ›")
                        st.json(people.model_dump())

                        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                        UIHelper.create_download_button(
                            people.model_dump(),
                            "extracted_people.json",
                            "application/json",
                            "ğŸ“¥ JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
                        )

                # è©³ç´°æƒ…å ±
                with st.expander("ğŸ“Š APIè©³ç´°æƒ…å ±", expanded=False):
                    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æƒ…å ±ã®å®‰å…¨ãªå–å¾—
                    response_info = {
                        "model": selected_model,
                        "id"   : getattr(response, 'id', 'N/A')
                    }

                    # usageæƒ…å ±ã®å®‰å…¨ãªå–å¾—
                    if hasattr(response, 'usage') and response.usage:
                        usage_obj = response.usage
                        if hasattr(usage_obj, 'model_dump'):
                            response_info["usage"] = usage_obj.model_dump()
                        elif hasattr(usage_obj, 'dict'):
                            response_info["usage"] = usage_obj.dict()
                        else:
                            response_info["usage"] = {
                                'prompt_tokens'    : getattr(usage_obj, 'prompt_tokens', 0),
                                'completion_tokens': getattr(usage_obj, 'completion_tokens', 0),
                                'total_tokens'     : getattr(usage_obj, 'total_tokens', 0)
                            }
                    else:
                        response_info["usage"] = {}

                    st.json(response_info)

            except Exception as e:
                st.error(f"æ§‹é€ åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
                logger.error(f"responses.parse error: {e}")
            finally:
                progress_bar.empty()
                status_text.empty()

    def show_message_history(self):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´è¡¨ç¤º"""
        with st.expander("ğŸ’¬ ä¼šè©±å±¥æ­´", expanded=False):
            messages = self.message_manager.get_messages()
            if messages:
                UIHelper.display_messages(messages, show_system=True)

                # å±¥æ­´æ“ä½œ
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚¯ãƒªã‚¢"):
                        self.message_manager.clear_messages()
                        st.rerun()
                with col2:
                    if st.button("ğŸ“¥ å±¥æ­´ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
                        export_data = self.message_manager.export_messages_ui()
                        UIHelper.create_download_button(
                            export_data,
                            "chat_history.json",
                            "application/json",
                            "ğŸ’¾ ä¿å­˜"
                        )
                with col3:
                    st.metric("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°", len(messages))
            else:
                st.info("ä¼šè©±å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")

    def run(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¢å®Ÿè¡Œ"""
        # ãƒšãƒ¼ã‚¸åˆæœŸåŒ–
        init_page("ğŸš€ Responses API åŸºæœ¬ãƒ‡ãƒ¢", sidebar_title="ğŸ“‹ æƒ…å ±ãƒ‘ãƒãƒ«")

        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        selected_model = select_model(self.demo_name)

        # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
        self.setup_sidebar(selected_model)

        # ãƒ¡ã‚¤ãƒ³ç”»é¢
        st.markdown("""
        ## ğŸ“– æ¦‚è¦
        ã“ã®ãƒ‡ãƒ¢ã§ã¯ OpenAI Responses API ã®åŸºæœ¬æ©Ÿèƒ½ã‚’ä½“é¨“ã§ãã¾ã™ï¼š
        - **responses.create**: è‡ªç„¶è¨€èªã§ã®å¯¾è©±
        - **responses.parse**: æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        """)

        # ã‚¿ãƒ–ã§ãƒ‡ãƒ¢ã‚’åˆ†é›¢
        tab1, tab2, tab3 = st.tabs(["ğŸ’¬ Create Demo", "ğŸ”„ Parse Demo", "ğŸ“ å±¥æ­´"])

        with tab1:
            self.responses_create_demo(selected_model)

        with tab2:
            self.responses_parse_demo(selected_model)

        with tab3:
            self.show_message_history()

        # ãƒ•ãƒƒã‚¿ãƒ¼
        st.markdown("---")
        st.markdown("""
        <div style='text-align: center; color: gray;'>
        ğŸ”§ <b>æ”¹ä¿®ç‰ˆ</b> - æ–°ã—ã„ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ | 
        ğŸ“Š å·¦ãƒšã‚¤ãƒ³ã§è©³ç´°æƒ…å ±ã‚’ç¢ºèªã§ãã¾ã™
        </div>
        """, unsafe_allow_html=True)


# ==================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨
# ==================================================
def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        demo = ResponsesSkeletonDemo()
        demo.run()
    except Exception as e:
        st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
        logger.error(f"Application error: {e}")

        if config.get("experimental.debug_mode", False):
            st.exception(e)


if __name__ == "__main__":
    main()

# streamlit run a20_00_responses_skeleton.py --server.port=8501
