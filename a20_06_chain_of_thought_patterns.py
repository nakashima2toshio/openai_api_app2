#
# chain_of_thought_patterns.py
# ==================================================
# Chain of Thought (CoT) ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
# ==================================================
# 5ç¨®é¡ã®ä»£è¡¨çš„ãªCoTãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè£…ã—ã€
# OpenAI APIã‚’ä½¿ç”¨ã—ã¦å®Ÿéš›ã«å‹•ä½œã‚’ç¢ºèªã§ãã¾ã™ã€‚
#
# [Usage] streamlit run chain_of_thought_patterns.py --server.port 8505
# ==================================================

import os
import sys
import json
from abc import ABC, abstractmethod
from pathlib import Path
from typing import List, Dict, Any, Optional, Union
from dataclasses import dataclass
from enum import Enum

import streamlit as st
from pydantic import BaseModel, Field
from openai import OpenAI
from openai.types.chat import (
    ChatCompletionMessageParam,
    ChatCompletionSystemMessageParam,
    ChatCompletionUserMessageParam,
    ChatCompletionAssistantMessageParam,
)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã®è¨­å®š
BASE_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(BASE_DIR))


# ==================================================
# è¨­å®šã¨ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
# ==================================================
@dataclass
class CoTConfig:
    """CoTãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¨­å®š"""
    page_title: str = "Chain of Thought Patterns"
    page_icon: str = "ğŸ§ "
    default_model: str = "gpt-4o-mini"
    json_compatible_models: List[str] = None

    def __post_init__(self):
        if self.json_compatible_models is None:
            self.json_compatible_models = [
                "gpt-4o", "gpt-4o-mini",
                "gpt-4-1106-preview", "gpt-3.5-turbo-1106"
            ]


class CoTPatternType(Enum):
    """CoTãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¨®é¡"""
    STEP_BY_STEP = "Step-by-Stepï¼ˆé€æ¬¡å±•é–‹å‹ï¼‰"
    HYPOTHESIS_TEST = "Hypothesis-Testï¼ˆä»®èª¬æ¤œè¨¼å‹ï¼‰"
    TREE_OF_THOUGHT = "Tree-of-Thoughtï¼ˆåˆ†å²æ¢ç´¢å‹ï¼‰"
    PROS_CONS_DECISION = "Pros-Cons-Decisionï¼ˆè³›å¦æ¯”è¼ƒå‹ï¼‰"
    PLAN_EXECUTE_REFLECT = "Plan-Execute-Reflectï¼ˆåå¾©æ”¹è‰¯å‹ï¼‰"


# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š
config = CoTConfig()


# ==================================================
# åŸºåº•ã‚¯ãƒ©ã‚¹
# ==================================================
class BaseCoTPattern(ABC):
    """
    CoTãƒ‘ã‚¿ãƒ¼ãƒ³ã®åŸºåº•ã‚¯ãƒ©ã‚¹

    å…¨ã¦ã®CoTãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå…±é€šã—ã¦æŒã¤æ©Ÿèƒ½ã‚’å®Ÿè£…
    """

    def __init__(self, pattern_type: CoTPatternType):
        self.pattern_type = pattern_type
        self.client = OpenAI()
        self.model = self._get_model()

    def _get_model(self) -> str:
        """é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        return st.session_state.get("selected_model", config.default_model)

    @abstractmethod
    def get_system_prompt(self) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ï¼ˆã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰"""
        pass

    @abstractmethod
    def get_result_model(self) -> BaseModel:
        """çµæœã®Pydanticãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰"""
        pass

    @abstractmethod
    def create_ui(self) -> Dict[str, Any]:
        """UIè¦ç´ ã‚’ä½œæˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å–å¾—ï¼ˆã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰"""
        pass

    @abstractmethod
    def parse_response(self, response_text: str, inputs: Dict[str, Any]) -> BaseModel:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦çµæœãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›ï¼ˆã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰"""
        pass

    def execute(self) -> Optional[BaseModel]:
        """CoTãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®Ÿè¡Œ"""
        st.subheader(f"ğŸ”¹ {self.pattern_type.value}")

        # UIä½œæˆã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å–å¾—
        inputs = self.create_ui()

        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        if not st.button("å®Ÿè¡Œ", key=f"execute_{self.pattern_type.name}"):
            return None

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        progress_bar = st.progress(0)
        status_text = st.empty()

        try:
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
            status_text.text("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆä¸­...")
            progress_bar.progress(20)

            messages = self._create_messages(inputs)

            # APIå‘¼ã³å‡ºã—
            status_text.text("APIã‚’å‘¼ã³å‡ºã—ä¸­...")
            progress_bar.progress(50)

            response = self._call_api(messages, inputs.get("temperature", 0.3))

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
            status_text.text("ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æä¸­...")
            progress_bar.progress(80)

            result = self.parse_response(response, inputs)

            # å®Œäº†
            progress_bar.progress(100)
            status_text.text("å®Œäº†!")

            # çµæœè¡¨ç¤º
            self._display_result(result)

            return result

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            if st.checkbox("è©³ç´°ã‚’è¡¨ç¤º", key=f"error_{self.pattern_type.name}"):
                st.exception(e)
            return None
        finally:
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
            progress_bar.empty()
            status_text.empty()

    def _create_messages(self, inputs: Dict[str, Any]) -> List[ChatCompletionMessageParam]:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚’ä½œæˆ"""
        system_prompt = self.get_system_prompt()
        user_content = self._format_user_content(inputs)

        return [
            ChatCompletionSystemMessageParam(role="system", content=system_prompt),
            ChatCompletionUserMessageParam(role="user", content=user_content)
        ]

    def _format_user_content(self, inputs: Dict[str, Any]) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®Ÿè£…ï¼‰"""
        # ã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰å¯èƒ½
        return "\n".join([f"{k}: {v}" for k, v in inputs.items() if k != "temperature"])

    def _call_api(self, messages: List[ChatCompletionMessageParam], temperature: float) -> str:
        """OpenAI APIã‚’å‘¼ã³å‡ºã—"""
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
        )
        return response.choices[0].message.content.strip()

    def _display_result(self, result: BaseModel):
        """çµæœã‚’è¡¨ç¤º"""
        # JSONå½¢å¼ã§è¡¨ç¤º
        with st.expander("ğŸ“Š çµæœï¼ˆJSONå½¢å¼ï¼‰", expanded=True):
            st.json(result.model_dump())

        # æ•´å½¢è¡¨ç¤º
        with st.expander("ğŸ“ çµæœï¼ˆæ•´å½¢è¡¨ç¤ºï¼‰", expanded=True):
            self._display_formatted_result(result)

    def _display_formatted_result(self, result: BaseModel):
        """æ•´å½¢ã•ã‚ŒãŸçµæœã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®Ÿè£…ï¼‰"""
        # ã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰å¯èƒ½
        for field, value in result.model_dump().items():
            if isinstance(value, list):
                st.write(f"**{field}:**")
                for item in value:
                    st.write(f"- {item}")
            else:
                st.write(f"**{field}:** {value}")


# ==================================================
# 1. Step-by-Stepï¼ˆé€æ¬¡å±•é–‹å‹ï¼‰
# ==================================================
class StepByStepResult(BaseModel):
    """Step-by-Stepãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµæœ"""
    question: str = Field(..., description="è³ªå•")
    steps: List[str] = Field(..., description="è§£æ±ºã‚¹ãƒ†ãƒƒãƒ—")
    answer: str = Field(..., description="æœ€çµ‚çš„ãªç­”ãˆ")


class StepByStepPattern(BaseCoTPattern):
    """
    Step-by-Stepï¼ˆé€æ¬¡å±•é–‹å‹ï¼‰ãƒ‘ã‚¿ãƒ¼ãƒ³

    ç”¨é€”: ç®—æ•°ãƒ»ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ»ãƒ¬ã‚·ãƒ”ç­‰ã®æ‰‹é †å‹ã‚¿ã‚¹ã‚¯
    """

    def __init__(self):
        super().__init__(CoTPatternType.STEP_BY_STEP)

    def get_system_prompt(self) -> str:
        return """You are a helpful tutor who thinks through problems step by step.
When given a question:
1. Break down the problem into clear, sequential steps
2. Number each step (Step 1:, Step 2:, etc.)
3. Show your work clearly
4. End with "Answer:" followed by the final answer

ã‚ãªãŸã¯å•é¡Œã‚’æ®µéšçš„ã«è€ƒãˆã‚‹è¦ªåˆ‡ãªãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
è³ªå•ãŒä¸ãˆã‚‰ã‚ŒãŸã‚‰ï¼š
1. å•é¡Œã‚’æ˜ç¢ºã§é †åºç«‹ã£ãŸã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†è§£ã—ã¦ãã ã•ã„
2. å„ã‚¹ãƒ†ãƒƒãƒ—ã«ç•ªå·ã‚’ä»˜ã‘ã¦ãã ã•ã„ï¼ˆStep 1:, Step 2: ãªã©ï¼‰
3. ä½œæ¥­ã‚’æ˜ç¢ºã«ç¤ºã—ã¦ãã ã•ã„
4. æœ€å¾Œã« "Answer:" ã«ç¶šã‘ã¦æœ€çµ‚çš„ãªç­”ãˆã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„"""

    def get_result_model(self) -> BaseModel:
        return StepByStepResult

    def create_ui(self) -> Dict[str, Any]:
        col1, col2 = st.columns([3, 1])

        with col1:
            question = st.text_input(
                "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                value="2X + 1 = 5  Xã¯ã„ãã¤ï¼Ÿ",
                help="æ®µéšçš„ã«è§£æ±ºã—ãŸã„å•é¡Œã‚’å…¥åŠ›"
            )

        with col2:
            temperature = st.slider(
                "Temperature",
                0.0, 1.0, 0.3, 0.05,
                help="ä½ã„å€¤ã»ã©ä¸€è²«æ€§ã®ã‚ã‚‹å›ç­”"
            )

        return {"question": question, "temperature": temperature}

    def parse_response(self, response_text: str, inputs: Dict[str, Any]) -> StepByStepResult:
        steps = []
        answer = ""

        for line in response_text.splitlines():
            line = line.strip()
            if line.lower().startswith("answer:"):
                answer = line.split(":", 1)[1].strip()
            elif line and (line[0].isdigit() or line.lower().startswith("step")):
                steps.append(line)

        return StepByStepResult(
            question=inputs["question"],
            steps=steps,
            answer=answer
        )

    def _display_formatted_result(self, result: StepByStepResult):
        st.write(f"**è³ªå•:** {result.question}")
        st.write("**è§£æ±ºã‚¹ãƒ†ãƒƒãƒ—:**")
        for step in result.steps:
            st.write(f"  {step}")
        st.write(f"**ç­”ãˆ:** {result.answer}")


# ==================================================
# 2. Hypothesis-Testï¼ˆä»®èª¬æ¤œè¨¼å‹ï¼‰
# ==================================================
class HypothesisTestResult(BaseModel):
    """Hypothesis-Testãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµæœ"""
    problem: str = Field(..., description="å•é¡Œ")
    hypothesis: str = Field(..., description="ä»®èª¬")
    evidence: List[str] = Field(default_factory=list, description="è¨¼æ‹ ãƒ»å®Ÿé¨“")
    evaluation: str = Field(..., description="è©•ä¾¡")
    conclusion: str = Field(..., description="çµè«–")


class HypothesisTestPattern(BaseCoTPattern):
    """
    Hypothesis-Testï¼ˆä»®èª¬æ¤œè¨¼å‹ï¼‰ãƒ‘ã‚¿ãƒ¼ãƒ³

    ç”¨é€”: ãƒã‚°è§£æãƒ»ç§‘å­¦å®Ÿé¨“ãƒ»A/Bãƒ†ã‚¹ãƒˆ
    """

    def __init__(self):
        super().__init__(CoTPatternType.HYPOTHESIS_TEST)

    def get_system_prompt(self) -> str:
        return """You are a senior QA engineer following a hypothesis-test methodology.
Given a problem and hypothesis, return a JSON object with these keys:
- "evidence": array of at least 3 concrete tests or measurements
- "evaluation": explanation of whether evidence supports/refutes the hypothesis
- "conclusion": short statement accepting or rejecting the hypothesis

Return ONLY valid JSON, no additional text.

ã‚ãªãŸã¯ä»®èª¬æ¤œè¨¼æ–¹æ³•è«–ã«å¾“ã†ä¸Šç´šQAã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
å•é¡Œã¨ä»®èª¬ãŒä¸ãˆã‚‰ã‚ŒãŸã‚‰ã€ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’æŒã¤JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
- "evidence": å°‘ãªãã¨ã‚‚3ã¤ã®å…·ä½“çš„ãªãƒ†ã‚¹ãƒˆã¾ãŸã¯æ¸¬å®šã®é…åˆ—
- "evaluation": è¨¼æ‹ ãŒä»®èª¬ã‚’æ”¯æŒ/åè¨¼ã™ã‚‹ã‹ã®èª¬æ˜
- "conclusion": ä»®èª¬ã‚’å—ã‘å…¥ã‚Œã‚‹ã‹æ‹’å¦ã™ã‚‹ã‹ã®çŸ­ã„å£°æ˜

æœ‰åŠ¹ãªJSONã®ã¿ã‚’è¿”ã—ã€è¿½åŠ ã®ãƒ†ã‚­ã‚¹ãƒˆã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚"""

    def get_result_model(self) -> BaseModel:
        return HypothesisTestResult

    def create_ui(self) -> Dict[str, Any]:
        problem = st.text_area(
            "å•é¡Œï¼ˆãƒã‚°ãƒ»å®Ÿé¨“ç›®çš„ï¼‰",
            value="ãƒ¢ãƒã‚¤ãƒ«ç‰ˆWebã‚¢ãƒ—ãƒªã®åˆå›è¡¨ç¤ºãŒé…ã„",
            height=80,
            help="è§£æ±ºã—ãŸã„å•é¡Œã‚„èª¿æŸ»ã—ãŸã„ç¾è±¡"
        )

        hypothesis = st.text_input(
            "ä»®èª¬ï¼ˆåŸå› ãƒ»æ”¹å–„æ¡ˆï¼‰",
            value="ç”»åƒã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¦å¸¯åŸŸã‚’åœ§è¿«ã—ã¦ã„ã‚‹",
            help="å•é¡Œã®åŸå› ã‚„è§£æ±ºç­–ã®ä»®èª¬"
        )

        col1, col2 = st.columns([1, 1])
        with col1:
            temperature = st.slider("Temperature", 0.0, 1.0, 0.2, 0.05)

        return {
            "problem"    : problem,
            "hypothesis" : hypothesis,
            "temperature": temperature
        }

    def _format_user_content(self, inputs: Dict[str, Any]) -> str:
        return f"Problem: {inputs['problem']}\nHypothesis: {inputs['hypothesis']}"

    def parse_response(self, response_text: str, inputs: Dict[str, Any]) -> HypothesisTestResult:
        try:
            data = json.loads(response_text)
        except json.JSONDecodeError:
            # JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ç°¡æ˜“çš„ãªãƒ‘ãƒ¼ã‚¹
            data = {
                "evidence"  : ["ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: æ‰‹å‹•ã§ç¢ºèªã—ã¦ãã ã•ã„"],
                "evaluation": response_text,
                "conclusion": "ä¸æ˜"
            }

        return HypothesisTestResult(
            problem=inputs["problem"],
            hypothesis=inputs["hypothesis"],
            evidence=data.get("evidence", []),
            evaluation=data.get("evaluation", ""),
            conclusion=data.get("conclusion", "")
        )


# ==================================================
# 3. Tree-of-Thoughtï¼ˆåˆ†å²æ¢ç´¢å‹ï¼‰
# ==================================================
class Branch(BaseModel):
    """æ€è€ƒã®åˆ†å²"""
    state: str = Field(..., description="ç¾åœ¨ã®çŠ¶æ…‹")
    action: str = Field(..., description="å–ã‚‹ã¹ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    score: Optional[float] = Field(None, description="è©•ä¾¡ã‚¹ã‚³ã‚¢")


class TreeOfThoughtResult(BaseModel):
    """Tree-of-Thoughtãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµæœ"""
    goal: str = Field(..., description="ç›®æ¨™")
    branches: List[Branch] = Field(default_factory=list, description="æ€è€ƒã®åˆ†å²")
    best_path: Optional[List[int]] = Field(None, description="æœ€é©ãƒ‘ã‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")
    result: str = Field(..., description="æœ€çµ‚çµæœ")


class TreeOfThoughtPattern(BaseCoTPattern):
    """
    Tree-of-Thoughtï¼ˆåˆ†å²æ¢ç´¢å‹ï¼‰ãƒ‘ã‚¿ãƒ¼ãƒ³

    ç”¨é€”: ãƒ‘ã‚ºãƒ«ãƒ»æœ€é©åŒ–ãƒ»ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ãƒ»ã‚²ãƒ¼ãƒ AI
    """

    def __init__(self):
        super().__init__(CoTPatternType.TREE_OF_THOUGHT)

    def get_system_prompt(self) -> str:
        return """You are an AI that performs Tree-of-Thoughts search.
Solve problems through branching reasoning steps.

For each problem:
1. Generate multiple candidate thoughts at each step
2. Evaluate each with a score (0-1)
3. Select the best path
4. Return a JSON with:
   - "branches": array of {state, action, score}
   - "best_path": array of selected indices
   - "result": final answer

Return ONLY valid JSON.

ã‚ãªãŸã¯Tree-of-Thoughtsæ¢ç´¢ã‚’å®Ÿè¡Œã™ã‚‹AIã§ã™ã€‚
åˆ†å²çš„ãªæ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã§å•é¡Œã‚’è§£æ±ºã—ã¾ã™ã€‚

å„å•é¡Œã«å¯¾ã—ã¦ï¼š
1. å„ã‚¹ãƒ†ãƒƒãƒ—ã§è¤‡æ•°ã®å€™è£œæ€è€ƒã‚’ç”Ÿæˆ
2. ãã‚Œãã‚Œã‚’0-1ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡
3. æœ€é©ãªãƒ‘ã‚¹ã‚’é¸æŠ
4. ä»¥ä¸‹ã‚’å«ã‚€JSONã‚’è¿”ã™ï¼š
   - "branches": {state, action, score}ã®é…åˆ—
   - "best_path": é¸æŠã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®é…åˆ—
   - "result": æœ€çµ‚çš„ãªç­”ãˆ

æœ‰åŠ¹ãªJSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"""

    def get_result_model(self) -> BaseModel:
        return TreeOfThoughtResult

    def create_ui(self) -> Dict[str, Any]:
        goal = st.text_input(
            "ç›®æ¨™ï¼ˆé”æˆã—ãŸã„ã‚¿ã‚¹ã‚¯ï¼‰",
            value="4, 9, 10, 13 ã®æ•°ã§Game of 24ã‚’è§£ã„ã¦ãã ã•ã„",
            help="æ¢ç´¢ã«ã‚ˆã£ã¦è§£æ±ºã—ãŸã„å•é¡Œ"
        )

        col1, col2, col3 = st.columns(3)

        with col1:
            num_branches = st.number_input(
                "åˆ†å²æ•°/ã‚¹ãƒ†ãƒƒãƒ—",
                min_value=2, max_value=6, value=3,
                help="å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®å€™è£œæ•°"
            )

        with col2:
            num_steps = st.number_input(
                "æ¢ç´¢ã‚¹ãƒ†ãƒƒãƒ—æ•°",
                min_value=1, max_value=5, value=2,
                help="æ¢ç´¢ã®æ·±ã•"
            )

        with col3:
            temperature = st.slider("Temperature", 0.0, 1.0, 0.5, 0.05)

        return {
            "goal"        : goal,
            "num_branches": num_branches,
            "num_steps"   : num_steps,
            "temperature" : temperature
        }

    def get_system_prompt(self) -> str:
        # å‹•çš„ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹å ´åˆ
        base_prompt = super().get_system_prompt()
        if hasattr(self, '_current_inputs'):
            base_prompt += f"\nUse exactly {self._current_inputs['num_branches']} branches and {self._current_inputs['num_steps']} steps."
        return base_prompt

    def _create_messages(self, inputs: Dict[str, Any]) -> List[ChatCompletionMessageParam]:
        # å…¥åŠ›ã‚’ä¸€æ™‚çš„ã«ä¿å­˜
        self._current_inputs = inputs
        return super()._create_messages(inputs)

    def parse_response(self, response_text: str, inputs: Dict[str, Any]) -> TreeOfThoughtResult:
        try:
            data = json.loads(response_text)
        except json.JSONDecodeError:
            data = {
                "branches" : [],
                "best_path": [],
                "result"   : "JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼"
            }

        branches = [Branch(**b) for b in data.get("branches", [])]

        return TreeOfThoughtResult(
            goal=inputs["goal"],
            branches=branches,
            best_path=data.get("best_path"),
            result=data.get("result", "")
        )


# ==================================================
# 4. Pros-Cons-Decisionï¼ˆè³›å¦æ¯”è¼ƒå‹ï¼‰
# ==================================================
class ProsConsDecisionResult(BaseModel):
    """Pros-Cons-Decisionãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµæœ"""
    topic: str = Field(..., description="ãƒˆãƒ”ãƒƒã‚¯")
    pros: List[str] = Field(default_factory=list, description="ãƒ¡ãƒªãƒƒãƒˆ")
    cons: List[str] = Field(default_factory=list, description="ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ")
    decision: str = Field(..., description="æ±ºå®š")
    rationale: str = Field(..., description="æ ¹æ‹ ")


class ProsConsDecisionPattern(BaseCoTPattern):
    """
    Pros-Cons-Decisionï¼ˆè³›å¦æ¯”è¼ƒå‹ï¼‰ãƒ‘ã‚¿ãƒ¼ãƒ³

    ç”¨é€”: æŠ€è¡“é¸å®šãƒ»æ„æ€æ±ºå®šãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»ä¼ç”»ææ¡ˆ
    """

    def __init__(self):
        super().__init__(CoTPatternType.PROS_CONS_DECISION)

    def get_system_prompt(self) -> str:
        return """You are a decision-making assistant.
Analyze topics by listing pros and cons, then make a reasoned decision.

Return a JSON object with:
- "pros": array of at least 3 advantages
- "cons": array of at least 3 disadvantages
- "decision": your recommendation
- "rationale": explanation for the decision

Be balanced and objective. Return ONLY valid JSON.

ã‚ãªãŸã¯æ„æ€æ±ºå®šæ”¯æ´ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãƒˆãƒ”ãƒƒã‚¯ã‚’åˆ†æã—ã€ç†æ€§çš„ãªæ±ºå®šã‚’ä¸‹ã—ã¾ã™ã€‚

ä»¥ä¸‹ã‚’å«ã‚€JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
- "pros": å°‘ãªãã¨ã‚‚3ã¤ã®åˆ©ç‚¹ã®é…åˆ—
- "cons": å°‘ãªãã¨ã‚‚3ã¤ã®æ¬ ç‚¹ã®é…åˆ—
- "decision": ã‚ãªãŸã®æ¨å¥¨
- "rationale": æ±ºå®šã®èª¬æ˜

ãƒãƒ©ãƒ³ã‚¹ã‚ˆãå®¢è¦³çš„ã«ã€‚æœ‰åŠ¹ãªJSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"""

    def get_result_model(self) -> BaseModel:
        return ProsConsDecisionResult

    def create_ui(self) -> Dict[str, Any]:
        topic = st.text_input(
            "æ„æ€æ±ºå®šã—ãŸã„ãƒˆãƒ”ãƒƒã‚¯",
            value="ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã‚ªãƒ•ã‚£ã‚¹å‡ºç¤¾ã€ã©ã¡ã‚‰ãŒè‰¯ã„ï¼Ÿ",
            help="æ¯”è¼ƒæ¤œè¨ã—ãŸã„ãƒˆãƒ”ãƒƒã‚¯ã‚„é¸æŠè‚¢"
        )

        temperature = st.slider(
            "Temperature",
            0.0, 1.0, 0.4, 0.05,
            help="é«˜ã„å€¤ã»ã©å‰µé€ çš„ãªå›ç­”"
        )

        return {"topic": topic, "temperature": temperature}

    def _format_user_content(self, inputs: Dict[str, Any]) -> str:
        return f"Topic: {inputs['topic']}"

    def parse_response(self, response_text: str, inputs: Dict[str, Any]) -> ProsConsDecisionResult:
        try:
            data = json.loads(response_text)
        except json.JSONDecodeError:
            data = {
                "pros"     : ["ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼"],
                "cons"     : ["ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼"],
                "decision" : "ä¸æ˜",
                "rationale": response_text
            }

        return ProsConsDecisionResult(
            topic=inputs["topic"],
            pros=data.get("pros", []),
            cons=data.get("cons", []),
            decision=data.get("decision", ""),
            rationale=data.get("rationale", "")
        )

    def _display_formatted_result(self, result: ProsConsDecisionResult):
        st.write(f"**ãƒˆãƒ”ãƒƒã‚¯:** {result.topic}")

        col1, col2 = st.columns(2)

        with col1:
            st.write("**ğŸ‘ ãƒ¡ãƒªãƒƒãƒˆ:**")
            for pro in result.pros:
                st.write(f"- {pro}")

        with col2:
            st.write("**ğŸ‘ ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ:**")
            for con in result.cons:
                st.write(f"- {con}")

        st.write(f"**ğŸ¯ æ±ºå®š:** {result.decision}")
        st.write(f"**ğŸ“ æ ¹æ‹ :** {result.rationale}")


# ==================================================
# 5. Plan-Execute-Reflectï¼ˆåå¾©æ”¹è‰¯å‹ï¼‰
# ==================================================
class PlanExecuteReflectResult(BaseModel):
    """Plan-Execute-Reflectãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµæœ"""
    objective: str = Field(..., description="ç›®æ¨™")
    plan: List[str] = Field(default_factory=list, description="è¨ˆç”»")
    execution_log: List[str] = Field(default_factory=list, description="å®Ÿè¡Œãƒ­ã‚°")
    reflect: str = Field(..., description="æŒ¯ã‚Šè¿”ã‚Š")
    next_plan: List[str] = Field(default_factory=list, description="æ¬¡ã®è¨ˆç”»")


class PlanExecuteReflectPattern(BaseCoTPattern):
    """
    Plan-Execute-Reflectï¼ˆåå¾©æ”¹è‰¯å‹ï¼‰ãƒ‘ã‚¿ãƒ¼ãƒ³

    ç”¨é€”: è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»é•·æœŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†
    """

    def __init__(self):
        super().__init__(CoTPatternType.PLAN_EXECUTE_REFLECT)

    def get_system_prompt(self) -> str:
        return """You are an AI implementing the Plan-Execute-Reflect loop.

Given an objective:
1. Plan: Create 3-5 concrete sequential steps
2. Execute: Simulate execution and log results
3. Reflect: Evaluate what worked and what didn't
4. Next Plan: Suggest 3 improved steps based on reflection

Return JSON with:
- "plan": array of initial steps
- "execution_log": array of simulated results
- "reflect": evaluation summary
- "next_plan": array of improved steps

Return ONLY valid JSON.

ã‚ãªãŸã¯Plan-Execute-Reflectãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè£…ã™ã‚‹AIã§ã™ã€‚

ç›®æ¨™ãŒä¸ãˆã‚‰ã‚ŒãŸã‚‰ï¼š
1. Plan: 3-5å€‹ã®å…·ä½“çš„ã§é †åºç«‹ã£ãŸã‚¹ãƒ†ãƒƒãƒ—ã‚’ä½œæˆ
2. Execute: å®Ÿè¡Œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—çµæœã‚’è¨˜éŒ²
3. Reflect: ä½•ãŒã†ã¾ãã„ãã€ä½•ãŒã†ã¾ãã„ã‹ãªã‹ã£ãŸã‹ã‚’è©•ä¾¡
4. Next Plan: æŒ¯ã‚Šè¿”ã‚Šã«åŸºã¥ã„ã¦3ã¤ã®æ”¹å–„ã•ã‚ŒãŸã‚¹ãƒ†ãƒƒãƒ—ã‚’ææ¡ˆ

ä»¥ä¸‹ã‚’å«ã‚€JSONã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
- "plan": åˆæœŸã‚¹ãƒ†ãƒƒãƒ—ã®é…åˆ—
- "execution_log": ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã•ã‚ŒãŸçµæœã®é…åˆ—
- "reflect": è©•ä¾¡ã®è¦ç´„
- "next_plan": æ”¹å–„ã•ã‚ŒãŸã‚¹ãƒ†ãƒƒãƒ—ã®é…åˆ—

æœ‰åŠ¹ãªJSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"""

    def get_result_model(self) -> BaseModel:
        return PlanExecuteReflectResult

    def create_ui(self) -> Dict[str, Any]:
        objective = st.text_input(
            "ç›®æ¨™ï¼ˆé”æˆã—ãŸã„ã“ã¨ï¼‰",
            value="3æ—¥ä»¥å†…ã«ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ä»•ä¸Šã’ã‚‹",
            help="é”æˆã—ãŸã„å…·ä½“çš„ãªç›®æ¨™"
        )

        temperature = st.slider(
            "Temperature",
            0.0, 1.0, 0.3, 0.05,
            help="ä½ã„å€¤ã»ã©ç¾å®Ÿçš„ãªè¨ˆç”»"
        )

        return {"objective": objective, "temperature": temperature}

    def _format_user_content(self, inputs: Dict[str, Any]) -> str:
        return f"Objective: {inputs['objective']}"

    def parse_response(self, response_text: str, inputs: Dict[str, Any]) -> PlanExecuteReflectResult:
        try:
            data = json.loads(response_text)
        except json.JSONDecodeError:
            data = {
                "plan"         : ["ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼"],
                "execution_log": [],
                "reflect"      : response_text,
                "next_plan"    : []
            }

        return PlanExecuteReflectResult(
            objective=inputs["objective"],
            plan=data.get("plan", []),
            execution_log=data.get("execution_log", []),
            reflect=data.get("reflect", ""),
            next_plan=data.get("next_plan", [])
        )


# ==================================================
# CoTãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
# ==================================================
class CoTPatternManager:
    """
    CoTãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµ±åˆç®¡ç†ã‚¯ãƒ©ã‚¹
    """

    def __init__(self):
        self.patterns: Dict[str, BaseCoTPattern] = {
            "Step-by-Stepï¼ˆé€æ¬¡å±•é–‹å‹ï¼‰"        : StepByStepPattern(),
            "Hypothesis-Testï¼ˆä»®èª¬æ¤œè¨¼å‹ï¼‰"     : HypothesisTestPattern(),
            "Tree-of-Thoughtï¼ˆåˆ†å²æ¢ç´¢å‹ï¼‰"     : TreeOfThoughtPattern(),
            "Pros-Cons-Decisionï¼ˆè³›å¦æ¯”è¼ƒå‹ï¼‰"  : ProsConsDecisionPattern(),
            "Plan-Execute-Reflectï¼ˆåå¾©æ”¹è‰¯å‹ï¼‰": PlanExecuteReflectPattern(),
        }
        self.client = OpenAI()

    def run(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ"""
        self._display_header()
        self._setup_sidebar()

        # é¸æŠã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®Ÿè¡Œ
        selected_pattern_name = st.session_state.get("selected_pattern")
        if selected_pattern_name and selected_pattern_name in self.patterns:
            pattern = self.patterns[selected_pattern_name]
            pattern.execute()

        self._display_footer()

    def _display_header(self):
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
        st.title("ğŸ§  Chain of Thought ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ãƒ„ãƒ¼ãƒ«")
        st.markdown("""
        ã“ã®ãƒ„ãƒ¼ãƒ«ã§ã¯ã€5ç¨®é¡ã®ä»£è¡¨çš„ãªChain of Thought (CoT)ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’
        å®Ÿéš›ã«å‹•ã‹ã—ã¦å­¦ç¿’ã§ãã¾ã™ã€‚
        """)

    def _setup_sidebar(self):
        """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š"""
        with st.sidebar:
            st.header("è¨­å®š")

            # ãƒ¢ãƒ‡ãƒ«é¸æŠ
            st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«é¸æŠ")
            selected_model = st.selectbox(
                "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
                config.json_compatible_models,
                index=config.json_compatible_models.index(config.default_model),
                help="JSONå‡ºåŠ›ã«å¯¾å¿œã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"
            )
            st.session_state["selected_model"] = selected_model

            # ãƒ‘ã‚¿ãƒ¼ãƒ³é¸æŠ
            st.subheader("ğŸ“š ãƒ‘ã‚¿ãƒ¼ãƒ³é¸æŠ")
            selected_pattern = st.radio(
                "CoTãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠ",
                list(self.patterns.keys()),
                help="å®Ÿè¡Œã—ãŸã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠ"
            )
            st.session_state["selected_pattern"] = selected_pattern

            # ãƒ‘ã‚¿ãƒ¼ãƒ³ã®èª¬æ˜
            st.subheader("ğŸ“– ãƒ‘ã‚¿ãƒ¼ãƒ³èª¬æ˜")
            pattern_descriptions = {
                "(1) Step-by-Stepï¼ˆé€æ¬¡å±•é–‹å‹ï¼‰"        :
                    "å•é¡Œã‚’é †åºç«‹ã¦ã¦æ®µéšçš„ã«è§£æ±ºã€‚ç®—æ•°å•é¡Œã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ãƒ¬ã‚·ãƒ”ãªã©ã«æœ€é©ã€‚",
                "(2) Hypothesis-Testï¼ˆä»®èª¬æ¤œè¨¼å‹ï¼‰"     :
                    "ä»®èª¬ã‚’ç«‹ã¦ã¦æ¤œè¨¼ã€‚ãƒã‚°è§£æã€ç§‘å­¦å®Ÿé¨“ã€A/Bãƒ†ã‚¹ãƒˆãªã©ã§ä½¿ç”¨ã€‚",
                "(3) Tree-of-Thoughtï¼ˆåˆ†å²æ¢ç´¢å‹ï¼‰"     :
                    "è¤‡æ•°ã®æ€è€ƒçµŒè·¯ã‚’æ¢ç´¢ã€‚ãƒ‘ã‚ºãƒ«ã€æœ€é©åŒ–ã€ã‚²ãƒ¼ãƒ AIãªã©ã«é©ç”¨ã€‚",
                "(4) Pros-Cons-Decisionï¼ˆè³›å¦æ¯”è¼ƒå‹ï¼‰"  :
                    "ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã‚’æ¯”è¼ƒã—ã¦æ±ºå®šã€‚æŠ€è¡“é¸å®šã€æ„æ€æ±ºå®šã«æœ‰åŠ¹ã€‚",
                "(5) Plan-Execute-Reflectï¼ˆåå¾©æ”¹è‰¯å‹ï¼‰":
                    "è¨ˆç”»ãƒ»å®Ÿè¡Œãƒ»æŒ¯ã‚Šè¿”ã‚Šã®ãƒ«ãƒ¼ãƒ—ã€‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã€è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ä½¿ç”¨ã€‚"
            }

            if selected_pattern in pattern_descriptions:
                st.info(pattern_descriptions[selected_pattern])

            # ãƒªã‚½ãƒ¼ã‚¹
            st.subheader("ğŸ”— å‚è€ƒãƒªã‚½ãƒ¼ã‚¹")
            st.markdown("""
            - [ä¿¡é ¼æ€§å‘ä¸Šãƒ†ã‚¯ãƒ‹ãƒƒã‚¯](https://cookbook.openai.com/articles/techniques_to_improve_reliability)
            - [GPT-4.1ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¬ã‚¤ãƒ‰](https://cookbook.openai.com/examples/gpt4-1_prompting_guide)
            - [Reasoning ãƒ¢ãƒ‡ãƒ«ã‚¬ã‚¤ãƒ‰](https://cookbook.openai.com/examples/reasoning_function_calls)
            """)

    def _display_footer(self):
        """ãƒ•ãƒƒã‚¿ãƒ¼è¡¨ç¤º"""
        st.markdown("---")

        # ä½¿ç”¨æ–¹æ³•
        with st.expander("ğŸ’¡ ä½¿ã„æ–¹ã®ãƒ’ãƒ³ãƒˆ"):
            st.markdown("""
            ### åŠ¹æœçš„ãªä½¿ã„æ–¹

            1. **Step-by-Step**: è¤‡é›‘ãªå•é¡Œã‚’å°ã•ãªã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†è§£ã—ãŸã„ã¨ã
            2. **Hypothesis-Test**: åŸå› ã‚’ç‰¹å®šã—ãŸã„ã¨ãã€ä»®èª¬ã‚’æ¤œè¨¼ã—ãŸã„ã¨ã
            3. **Tree-of-Thought**: è¤‡æ•°ã®å¯èƒ½æ€§ã‚’æ¢ç´¢ã—ãŸã„ã¨ã
            4. **Pros-Cons-Decision**: é¸æŠè‚¢ã‚’æ¯”è¼ƒæ¤œè¨ã—ãŸã„ã¨ã
            5. **Plan-Execute-Reflect**: ç¶™ç¶šçš„ãªæ”¹å–„ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯

            ### Temperatureè¨­å®š
            - **0.0-0.3**: ä¸€è²«æ€§ã®ã‚ã‚‹è«–ç†çš„ãªå›ç­”
            - **0.4-0.6**: ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸå›ç­”
            - **0.7-1.0**: å‰µé€ çš„ã§å¤šæ§˜ãªå›ç­”
            """)

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        if st.checkbox("ğŸ› ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º"):
            col1, col2 = st.columns(2)

            with col1:
                st.metric("é¸æŠä¸­ã®ãƒ¢ãƒ‡ãƒ«", st.session_state.get("selected_model", "æœªé¸æŠ"))
                st.metric("é¸æŠä¸­ã®ãƒ‘ã‚¿ãƒ¼ãƒ³", st.session_state.get("selected_pattern", "æœªé¸æŠ"))

            with col2:
                st.metric("OpenAI API Key", "è¨­å®šæ¸ˆã¿" if os.getenv("OPENAI_API_KEY") else "æœªè¨­å®š")
                st.metric("ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°æ•°", len(st.session_state))


# ==================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ==================================================
def check_environment():
    """ç’°å¢ƒãƒã‚§ãƒƒã‚¯"""
    if not os.getenv("OPENAI_API_KEY"):
        st.error("âš ï¸ ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        st.info("""
        ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§è¨­å®šã—ã¦ãã ã•ã„:
        ```bash
        export OPENAI_API_KEY='your-api-key'
        ```
        """)
        st.stop()


def display_examples():
    """ä½¿ç”¨ä¾‹ã®è¡¨ç¤º"""
    with st.expander("ğŸ“ ä½¿ç”¨ä¾‹"):
        st.markdown("""
        ### Step-by-Step ã®ä¾‹
        **è³ªå•**: ã€Œ2X + 1 = 5 Xã¯ã„ãã¤ï¼Ÿã€
        **æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
        - Step 1: ä¸¡è¾ºã‹ã‚‰1ã‚’å¼•ã â†’ 2X = 4
        - Step 2: ä¸¡è¾ºã‚’2ã§å‰²ã‚‹ â†’ X = 2
        - Answer: X = 2

        ### Hypothesis-Test ã®ä¾‹
        **å•é¡Œ**: ã€ŒWebã‚¢ãƒ—ãƒªãŒé…ã„ã€
        **ä»®èª¬**: ã€Œç”»åƒãŒå¤§ãã™ãã‚‹ã€
        **æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
        - Evidence: [ç”»åƒã‚µã‚¤ã‚ºæ¸¬å®š, é€šä¿¡é‡åˆ†æ, åœ§ç¸®ãƒ†ã‚¹ãƒˆ]
        - Evaluation: è¨¼æ‹ ã¯ä»®èª¬ã‚’æ”¯æŒ
        - Conclusion: ä»®èª¬ã‚’æ¡æŠ

        ### Tree-of-Thought ã®ä¾‹
        **ç›®æ¨™**: ã€ŒGame of 24ã‚’è§£ãã€
        **æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
        - è¤‡æ•°ã®è¨ˆç®—çµŒè·¯ã‚’æ¢ç´¢
        - å„çµŒè·¯ã«ã‚¹ã‚³ã‚¢ä»˜ã‘
        - æœ€é©è§£ã‚’é¸æŠ
        """)


# ==================================================
# ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¿½åŠ ä¾‹
# ==================================================
class CustomCoTPattern(BaseCoTPattern):
    """
    ã‚«ã‚¹ã‚¿ãƒ CoTãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

    ã“ã®ã‚¯ãƒ©ã‚¹ã‚’å‚è€ƒã«ã€ç‹¬è‡ªã®CoTãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆã§ãã¾ã™
    """

    class CustomResult(BaseModel):
        """ã‚«ã‚¹ã‚¿ãƒ çµæœãƒ¢ãƒ‡ãƒ«"""
        input_data: str
        processed_data: str
        insights: List[str]

    def __init__(self):
        super().__init__(CoTPatternType.STEP_BY_STEP)  # ä»®ã®å‹
        self.pattern_name = "Custom Pattern"

    def get_system_prompt(self) -> str:
        return "Your custom system prompt here..."

    def get_result_model(self) -> BaseModel:
        return self.CustomResult

    def create_ui(self) -> Dict[str, Any]:
        user_input = st.text_area("ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›", height=100)
        return {"input": user_input}

    def parse_response(self, response_text: str, inputs: Dict[str, Any]) -> BaseModel:
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ¼ã‚¹å‡¦ç†
        return self.CustomResult(
            input_data=inputs["input"],
            processed_data=response_text,
            insights=["ã‚«ã‚¹ã‚¿ãƒ æ´å¯Ÿ1", "ã‚«ã‚¹ã‚¿ãƒ æ´å¯Ÿ2"]
        )


# ==================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ==================================================
def main():
    # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
    # ãƒšãƒ¼ã‚¸è¨­å®š
    st.set_page_config(
        page_title=config.page_title,
        page_icon=config.page_icon,
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # ç’°å¢ƒãƒã‚§ãƒƒã‚¯
    check_environment()

    # ä½¿ç”¨ä¾‹ã®è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    display_examples()

    # ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®å®Ÿè¡Œ
    manager = CoTPatternManager()
    manager.run()


if __name__ == "__main__":
    main()

