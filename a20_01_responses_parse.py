# streamlit run a20_01_responses_parse.py --server.port 8501
# port Check: lsof -i :5678
# æ¨è«–ãŒæœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦Responses APIã« API ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
# OpenAI API: https://platform.openai.com/docs/api-reference/introduction
# Streamlit API: https://docs.streamlit.io/develop/api-reference
# ----------------------------------------
# [Menu] OpenAI APIã®æ¦‚è¦
# 01_01  Responsesã‚µãƒ³ãƒ—ãƒ«
# 01_011 Responsesã‚µãƒ³ãƒ—ãƒ«
# 01_02  ç”»åƒå…¥åŠ›(URL)
# 01_021 ç”»åƒå…¥åŠ›(base64)
# 01_03  æ§‹é€ åŒ–å‡ºåŠ›-responses.create-API
# 01_031 æ§‹é€ åŒ–å‡ºåŠ›-responses.parse-API
# 01_04  é–¢æ•° calling
# 01_05  ä¼šè©±çŠ¶æ…‹
# 01_06  ãƒ„ãƒ¼ãƒ«:FileSearch, WebSearch
# 01_061 File Search
# 01_062 Web Search
# 01_07  Computer Use Tool Param
# ----------------------------------------
import os
import sys

sys.path.insert(
    0, os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
)

import json
import base64
import glob
import requests
from pathlib import Path
import pandas as pd

from openai import OpenAI
from openai.types.responses.web_search_tool_param import UserLocation

from openai.types.responses import (
    EasyInputMessageParam,      # åŸºæœ¬ã®å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    ResponseInputTextParam,     # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
    ResponseInputImageParam,    # å…¥åŠ›ç”»åƒ
    ResponseFormatTextJSONSchemaConfigParam,  # Structured output ç”¨
    ResponseTextConfigParam,    # Structured output ç”¨
    FunctionToolParam,          # é–¢æ•°å‘¼ã³å‡ºã—ãƒ„ãƒ¼ãƒ«
    FileSearchToolParam,        # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ„ãƒ¼ãƒ«
    WebSearchToolParam,         # Web æ¤œç´¢ãƒ„ãƒ¼ãƒ«
    ComputerToolParam,          #
    Response
)

from pydantic import BaseModel, ValidationError

BASE_DIR = Path(__file__).resolve().parent.parent
THIS_DIR = Path(__file__).resolve().parent
DATASETS_DIR = os.path.join(BASE_DIR, 'datasets')

from helper import (
    init_page,
    init_messages,
    select_model,
    sanitize_key,
    get_default_messages,
    extract_text_from_response, append_user_message,
)

import streamlit as st

# --- ã‚¤ãƒ³ãƒãƒ¼ãƒˆç›´å¾Œã«ï¼‘åº¦ã ã‘å®Ÿè¡Œã™ã‚‹ ---
st.set_page_config(
    page_title="ChatGPT Responses API",
    page_icon="2025-5 Nakashima"
)

# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ URL
image_path_sample = (
    "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/"
    "Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-"
    "Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
)

# ==================================================
# 01_00 ãƒ†ã‚­ã‚¹ãƒˆå…¥å‡ºåŠ› (One Shot):responses.create
# ==================================================
def responses_parse_basic(demo_name: str = "01_00_responses_parse_basic"):
    class UserInfo(BaseModel):
        name: str
        age: int
        city: str

    # ãƒ«ãƒ¼ãƒˆã‚’ object ã«ã—ã€ãã®ä¸­ã«é…åˆ—ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç½®ã
    class People(BaseModel):
        users: list[UserInfo]

    model = select_model(demo_name)
    st.write("é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«:", model)
    client = OpenAI()

    safe = sanitize_key(demo_name)
    st.write(
        "(è¨˜å…¥ä¾‹ï¼š"
        "ç§ã®åå‰ã¯ç”°ä¸­å¤ªéƒã€30æ­³ã€æ±äº¬åœ¨ä½ã§ã™ã€‚"
        "ç§ã®åå‰ã¯éˆ´æœ¨å¥å¤ªã€28æ­³ã€å¤§é˜ªåœ¨ä½ã§ã™ã€‚"
    )
    with st.form(key=f"responses_form_{safe}"):
        user_input = st.text_area("ã“ã“ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", height=100)
        submitted = st.form_submit_button("é€ä¿¡")

    if submitted and user_input.strip():
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå´ã§ã€Œusers é…åˆ—ã§è¿”ã—ã¦ã€ã¨æ˜ç¤º
        messages = get_default_messages()
        append_developer_text = "ã‚ãªãŸã¯æƒ…å ±æŠ½å‡ºã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        messages.append(
            EasyInputMessageParam(
                role="developer",
                content=[
                    ResponseInputTextParam(type="input_text", text=append_developer_text),
                ]
            )
        )
        append_user_text = (
            "ç§ã®åå‰ã¯ç”°ä¸­å¤ªéƒã€30æ­³ã€æ±äº¬åœ¨ä½ã§ã™ã€‚"
            "ç§ã®åå‰ã¯éˆ´æœ¨å¥å¤ªã€28æ­³ã€å¤§é˜ªåœ¨ä½ã§ã™ã€‚"
        )
        messages.append(
            EasyInputMessageParam(
                role="user",
                content=[
                    ResponseInputTextParam(type="input_text", text=append_user_text),
                ]
            )
        )

        response = client.responses.parse(
            model=model,
            input=messages,
            text_format=People
        )

        people: People = response.output_parsed
        for p in people.users:
            output = f"{p.name} / {p.age} / {p.city}"
            st.write(output)


# ==================================================
# 01_01 ãƒ†ã‚­ã‚¹ãƒˆå…¥å‡ºåŠ› (One Shot):responses.create
# ==================================================
def responses_sample(demo_name: str = "01_01_responses_One_Shot"):
    init_messages(demo_name)
    st.write(f"# {demo_name}")
    model = select_model(demo_name)
    st.write("é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«:", model)

    safe = sanitize_key(demo_name)
    with st.form(key=f"responses_form_{safe}"):
        user_input = st.text_area("ã“ã“ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", height=75)
        submitted = st.form_submit_button("é€ä¿¡")

    messages = get_default_messages()
    if submitted and user_input:
        st.write("å…¥åŠ›å†…å®¹:", user_input)
        messages.append(EasyInputMessageParam(role="user", content=user_input))
        client = OpenAI()
        res = client.responses.create(model=model, input=messages)
        for i, txt in enumerate(extract_text_from_response(res), 1):
            st.code(txt)

        with st.form(key=f"responses_next_{safe}"):
            if st.form_submit_button("æ¬¡ã®è³ªå•"):
                st.rerun()


# ==================================================
# 01_011 ãƒ†ã‚­ã‚¹ãƒˆå…¥å‡ºåŠ› + history: responses.create
# ==================================================
def responses_memory_sample(demo_name: str = "01_011_responses_memory"):
    init_messages(demo_name)
    st.write(f"# {demo_name}")
    model = select_model(demo_name)
    st.write("é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«:", model)

    messages = get_default_messages()
    if "responses_memory_history" not in st.session_state:
        st.session_state.responses_memory_history = messages

    # å±¥æ­´è¡¨ç¤º
    for msg in st.session_state.responses_memory_history:
        role = msg["role"]
        if role == "user":
            st.markdown(f"**User:** {msg['content']}")
        elif role == "assistant":
            st.markdown(f"<span style='color:green'><b>Assistant:</b> {msg['content']}</span>", unsafe_allow_html=True)
        elif role == "developer":
            st.markdown(f"<span style='color:gray'><i>System:</i> {msg['content']}</span>", unsafe_allow_html=True)

    safe = sanitize_key(demo_name)
    with st.form(key=f"qam_form_{safe}"):
        user_input = st.text_area("ã“ã“ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", height=75, key=f"memory_input_{safe}")
        submitted = st.form_submit_button("é€ä¿¡")

    if submitted and user_input:
        st.session_state.responses_memory_history.append(EasyInputMessageParam(role="user", content=user_input))
        client = OpenAI()
        res = client.responses.create(model=model, input=st.session_state.responses_memory_history)
        for txt in extract_text_from_response(res):
            st.session_state.responses_memory_history.append(EasyInputMessageParam(role="assistant", content=txt))
        st.rerun()

    if st.button("ä¼šè©±å±¥æ­´ã‚¯ãƒªã‚¢", key=f"memory_clear_{safe}"):
        st.session_state.responses_memory_history = messages
        st.rerun()


# ==================================================
# 01_02 ç”»åƒå…¥åŠ› (URL):responses.create , ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›
# ==================================================
def responses_01_02_passing_url(demo_name: str = "01_02_Image_URL"):
    init_messages(demo_name)
    model = select_model(demo_name)
    st.write("é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«:", model)

    safe = sanitize_key(demo_name)
    image_url = st.text_input("ç”»åƒURLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value=image_path_sample, key=f"img_url_{safe}")
    question_text = "ã“ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’èª¬æ˜ã—ãªã•ã„ã€‚"

    with st.form(key=f"responses_img_form_{safe}"):
        submitted = st.form_submit_button("ç”»åƒã§è³ªå•")

    messages = get_default_messages()
    if submitted:
        client = OpenAI()
        messages.append(
            EasyInputMessageParam(
                role="user",
                content=[
                    ResponseInputTextParam(type="input_text", text=question_text),
                    ResponseInputImageParam(type="input_image", image_url=image_url, detail="auto"),
                ],
            )
        )
        res = client.responses.create(model=model, input=messages)
        st.write(getattr(res, "output_text", str(res)))


# ==================================================
# 01_021 ç”»åƒå…¥åŠ› (base64):responses.create
# ==================================================
def encode_image(path: str) -> str:
    with open(path, "rb") as f:
        return base64.b64encode(f.read()).decode()


def responses_01_021_base64_image(demo_name: str = "01_021_Image_Base64"):
    init_messages(demo_name)
    st.write(f"# {demo_name}")
    model = select_model(demo_name)
    st.write("é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«:", model)

    image_dir = "images/"
    safe = sanitize_key(demo_name)
    files = sorted(
        glob.glob(f"{image_dir}/*.png") + glob.glob(f"{image_dir}/*.jpg") +
        glob.glob(f"{image_dir}/*.jpeg") + glob.glob(f"{image_dir}/*.webp") +
        glob.glob(f"{image_dir}/*.gif")
    )
    if not files:
        st.warning(f"ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {image_dir} ã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    file_path = st.selectbox("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", files, key=f"img_select_{safe}")

    with st.form(key=f"img_b64_form_{safe}"):
        submitted = st.form_submit_button("é¸æŠç”»åƒã§å®Ÿè¡Œ")

    if submitted:
        b64 = encode_image(file_path)
        st.image(file_path, caption="é¸æŠç”»åƒ", width=320)
        messages = get_default_messages()
        messages.append(
            EasyInputMessageParam(
                role="user",
                content=[
                    ResponseInputTextParam(type="input_text", text="what's in this image?"),
                    ResponseInputImageParam(type="input_image", image_url=f"data:image/jpeg;base64,{b64}",
                                            detail="auto"),
                ],
            ),
        )
        res = OpenAI().responses.create(model=model, input=messages)
        st.subheader("å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆ:")
        st.write(getattr(res, "output_text", str(res)))


# ==================================================
# 01_03 æ§‹é€ åŒ–å‡ºåŠ› (JSON Schema):responses.create
# ==================================================

# ------------- Pydantic ãƒ¢ãƒ‡ãƒ« -------------
class Event(BaseModel):
    name: str
    date: str
    participants: list[str]


# ------------- å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----------------
def responses_01_03_structured_output(demo_name: str = "01_03_Structured_Output") -> None:
    # Structured Outputs ãƒ‡ãƒ¢ (parse_raw å»ƒæ­¢å¯¾å¿œ)

    init_messages(demo_name)
    st.header("1. structured_output: ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±æŠ½å‡ºãƒ‡ãƒ¢")
    safe = sanitize_key(demo_name)

    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
        ["gpt-4.1", "o4-mini", "gpt-4o-2024-08-06", "gpt-4o-mini"],
        key=f"struct_model_{safe}",
    )

    # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
    text = st.text_input(
        "ã‚¤ãƒ™ãƒ³ãƒˆè©³ç´°ã‚’å…¥åŠ›",
        "(ä¾‹)å°æ¹¾ãƒ•ã‚§ã‚¹2025 ï½ã‚ã¤ã¾ã‚Œï¼ç©¶æ¥µã®å°æ¹¾ã‚°ãƒ«ãƒ¡ï½ in Kawasaki Spark",
        key=f"struct_input_{safe}",
    )
    st.write("(ä¾‹)å°æ¹¾ãƒ•ã‚§ã‚¹2025 ï½ã‚ã¤ã¾ã‚Œï¼ç©¶æ¥µã®å°æ¹¾ã‚°ãƒ«ãƒ¡ï½ in Kawasaki Spark")

    if st.button("å®Ÿè¡Œï¼šã‚¤ãƒ™ãƒ³ãƒˆæŠ½å‡º", key=f"struct_btn_{safe}"):
        # 1. JSON Schema
        schema = {
            "type"                : "object",
            "properties"          : {
                "name"        : {"type": "string"},
                "date"        : {"type": "string"},
                "participants": {"type": "array", "items": {"type": "string"}},
            },
            "required"            : ["name", "date", "participants"],
            "additionalProperties": False,
        }

        # 2. å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        messages: list[EasyInputMessageParam] = [
            EasyInputMessageParam(role="developer", content="Extract event details from the text."),
            EasyInputMessageParam(role="user", content=[ResponseInputTextParam(type="input_text", text=text)]),
        ]

        # 3. Structured Output æŒ‡å®š (æœ€æ–° SDK ã¯ text=ResponseTextConfigParam)
        text_cfg = ResponseTextConfigParam(
            format=ResponseFormatTextJSONSchemaConfigParam(
                name="event_extraction",
                type="json_schema",
                schema=schema,
                strict=True,
            )
        )

        # 4. API å‘¼ã³å‡ºã—
        client = OpenAI()
        res = client.responses.create(model=model, input=messages, text=text_cfg)

        # 5. Pydantic ã§ãƒãƒªãƒ‡ãƒ¼ãƒˆ
        try:
            event: Event = Event.model_validate_json(res.output_text)
            st.subheader("æŠ½å‡ºçµæœ (Pydantic)")
            st.json(event.model_dump())
            st.code(repr(event), language="python")
        except (ValidationError, json.JSONDecodeError) as err:
            st.error("å‡ºåŠ›ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.exception(err)


# ==================================================
# 01_031 æ§‹é€ åŒ–å‡ºåŠ› (JSON Schema):responses.parse
# ==================================================
# --- 1. Pydantic ãƒ¢ãƒ‡ãƒ« ---
class Event2(BaseModel):
    name: str
    date: str
    participants: list[str]


# --- 2. ã‚³ã‚¢é–¢æ•° ---
def responses_01_031_structured_output(demo_name: str = "01_03_Structured_Output"):
    init_messages(demo_name)
    safe = sanitize_key(demo_name)
    st.header("1. structured_output: ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±æŠ½å‡ºãƒ‡ãƒ¢")

    model = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
        ["o4-mini", "gpt-4o-2024-08-06", "gpt-4o-mini"],
        key=f"struct_model_{safe}",
    )
    text = st.text_input(
        "ã‚¤ãƒ™ãƒ³ãƒˆè©³ç´°ã‚’å…¥åŠ›",
        "(ä¾‹)å°æ¹¾ãƒ•ã‚§ã‚¹2025 ï½ã‚ã¤ã¾ã‚Œï¼ç©¶æ¥µã®å°æ¹¾ã‚°ãƒ«ãƒ¡ï½ in Kawasaki Spark",
        key=f"struct_input_{safe}",
    )

    if st.button("å®Ÿè¡Œï¼šã‚¤ãƒ™ãƒ³ãƒˆæŠ½å‡º", key=f"struct_btn_{safe}"):
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‹ä»˜ãã§ç”¨æ„
        messages: list[EasyInputMessageParam] = [
            EasyInputMessageParam(
                role="developer",
                content="Extract event details from the text."
            ),
            EasyInputMessageParam(
                role="user",
                content=[ResponseInputTextParam(type="input_text", text=text)],
            ),
        ]

        # 3. parse helper ã‚’ä½¿ç”¨
        client = OpenAI()
        res = client.responses.parse(
            model=model,
            input=messages,
            text_format=Event2,  # â† ã“ã“ãŒãƒã‚¤ãƒ³ãƒˆ
        )

        # 4. è¿”å´ã¯è‡ªå‹•ã§ Event2 ã«ï¼
        try:
            event: Event2 = res.output_parsed  # SDK ãŒç”Ÿæˆ
            st.subheader("æŠ½å‡ºçµæœ (Pydantic)")
            st.json(event.model_dump())
            st.code(repr(event), language="python")
        except (ValidationError, AttributeError) as ve:
            st.error("Pydantic ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.exception(ve)


# ==================================================
# 01_04 é–¢æ•°å‘¼ã³å‡ºã— (OpenWeatherMap): Function calling by use json-format
# ==================================================
function_tool_param: FunctionToolParam = {
    "name"       : "get_current_weather",
    "description": "æŒ‡å®šéƒ½å¸‚ã®ç¾åœ¨ã®å¤©æ°—ã‚’è¿”ã™",
    "parameters" : {
        "type"      : "object",
        "properties": {
            "location": {"type": "string"},
            "unit"    : {"type": "string", "enum": ["celsius", "fahrenheit"]},
        },
        "required"  : ["location"],
    },
    "strict"     : True,
    "type"       : "function",
}


def load_japanese_cities(csv_path: str) -> pd.DataFrame:
    df = pd.read_csv(csv_path)
    jp = df[df["country"] == "Japan"][["name", "lat", "lon"]].drop_duplicates()
    return jp.sort_values("name").reset_index(drop=True)


def select_city(df_jp: pd.DataFrame, demo_name: str = ""):
    safe = sanitize_key(demo_name)
    city = st.selectbox("éƒ½å¸‚ã‚’é¸æŠã—ã¦ãã ã•ã„", df_jp["name"].tolist(), key=f"city_{safe}")
    row = df_jp[df_jp["name"] == city].iloc[0]
    return city, row["lat"], row["lon"]

def get_current_weather_by_coords(lat: float, lon: float, unit: str = "metric"):
    api_key = os.getenv("OPENWEATHER_API_KEY")
    if not api_key:
        raise RuntimeError("OPENWEATHER_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    url = f"http://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={api_key}&units={unit}"
    res = requests.get(url)
    res.raise_for_status()
    data = res.json()
    return {
        "city"       : data["name"],
        "temperature": data["main"]["temp"],
        "description": data["weather"][0]["description"],
        "coord"      : data["coord"],
    }


def get_weekly_forecast(lat: float, lon: float, unit: str = "metric"):
    api_key = os.getenv("OPENWEATHER_API_KEY")
    if not api_key:
        raise RuntimeError("OPENWEATHER_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    url = f"http://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&units={unit}&appid={api_key}"
    res = requests.get(url)
    res.raise_for_status()
    data = res.json()
    daily: dict[str, dict[str, list[float] | str]] = {}
    for item in data["list"]:
        date = item["dt_txt"].split(" ")[0]
        temp = item["main"]["temp"]
        weather = item["weather"][0]["description"]
        daily.setdefault(date, {"temps": [], "weather": weather})["temps"].append(temp)
    return [
        {"date": d, "temp_avg": round(sum(v["temps"]) / len(v["temps"]), 1), "weather": v["weather"]}
        for d, v in daily.items()
    ]


def responses_01_04_function_calling(demo_name: str = "01_04_Function_Calling"):
    init_messages(demo_name)
    model = select_model(demo_name)
    st.write("é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«:", model)

    df_jp = load_japanese_cities("data/cities_list.csv")
    city, lat, lon = select_city(df_jp, demo_name)

    today = get_current_weather_by_coords(lat, lon)
    st.write("----- æœ¬æ—¥ã®å¤©æ°— -----")
    st.write(f"éƒ½å¸‚ : {today['city']}")
    st.write(f"æ°—æ¸© : {today['temperature']}â„ƒ")
    st.write(f"èª¬æ˜ : {today['description']}")

    st.write("----- 5æ—¥é–“äºˆå ± ï¼ˆ3æ™‚é–“æ¯ã‚’æ—¥åˆ¥å¹³å‡ï¼‰ -----")
    for day in get_weekly_forecast(lat, lon):
        st.write(f"{day['date']} : {day['temp_avg']}â„ƒ, {day['weather']}")


# --------------------------------------------------
# 01_05ã€€ä¼šè©±çŠ¶æ…‹
# --------------------------------------------------
def responses_01_05_conversation(demo_name: str = "01_05_Conversation"):
    init_messages(demo_name)
    model = select_model(demo_name)
    st.write("é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«:", model)


# --------------------------------------------------
# 01_06 Built-in Tools (FileSearch / WebSearch)
# --------------------------------------------------
def responses_01_06_tools_file_search(demo_name: str = "01_06_Extend_Model") -> None:
    # FileSearch / WebSearch ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ãƒ‡ãƒ¢ï¼ˆæ”¹è¨‚ç‰ˆï¼‰
    init_messages(demo_name)

    model = select_model(demo_name)
    st.write("é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«:", model)

    # --- UI -----------------------------------------------------------
    tool_choice = st.selectbox("ãƒ„ãƒ¼ãƒ«é¸æŠ", ["file_search", "web_search_preview"], key=f"tool_{demo_name}")
    query = st.text_input("ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›", "", key=f"query_{demo_name}")

    # FileSearch ç”¨è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    vector_store_id: str | None = None
    max_results: int = 5
    if tool_choice == "file_search":
        vector_store_id = st.text_input("vector_store_id", "", key=f"vs_{demo_name}")
        max_results = st.number_input("æœ€å¤§å–å¾—æ•°", 1, 20, 5, key=f"max_{demo_name}")

    # --- å®Ÿè¡Œ ---------------------------------------------------------
    if st.button("é€ä¿¡ï¼ˆToolsï¼‰", key=f"btn_{demo_name}"):
        client = OpenAI()

        if tool_choice == "file_search":
            # 1. FileSearchToolParam ã‚’ç”Ÿæˆ
            fs_tool = FileSearchToolParam(
                type="file_search",
                vector_store_ids=[vector_store_id] if vector_store_id else [],
                max_num_results=int(max_results),
            )

            # 2. Responses API å‘¼ã³å‡ºã—ï¼ˆæ¤œç´¢çµæœã‚’åŒæ™‚è¿”å´ï¼‰
            resp = client.responses.create(
                model=model,
                tools=[fs_tool],
                input=query,
                include=["file_search_call.results"],  # ğŸ”‘ ã“ã“ãŒæ–°è¦
            )

            # 3. çµæœè¡¨ç¤º
            st.subheader("ãƒ¢ãƒ‡ãƒ«å›ç­”")
            st.write(getattr(resp, "output_text", str(resp)))

            st.subheader("FileSearch çµæœ")
            if resp.file_search_call and resp.file_search_call.results:
                st.json(resp.file_search_call.results)
            else:
                st.info("æ¤œç´¢çµæœãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚vector_store_id ã¨ã‚¯ã‚¨ãƒªã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        else:  # --- web_search_preview ----------------------------------
            ws_tool = WebSearchToolParam(
                type="web_search_preview",
                search_context_size="medium",
            )
            resp = client.responses.create(model=model, tools=[ws_tool], input=query)
            st.subheader("ãƒ¢ãƒ‡ãƒ«å›ç­”")
            st.write(getattr(resp, "output_text", str(resp)))


# --------------------------------------------------
# 01_061 Built-in Tools (FileSearch)
# æƒ³å®šã‚·ãƒŠãƒªã‚ª
# ------------
# FileSearch
# è‡ªå‰ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆPDFï¼MDï¼DOCX ãªã©ï¼‰ã‚’å¯¾è±¡ã«ã€
# ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’è¡Œã„ã€ãƒ¢ãƒ‡ãƒ«å›ç­”ã®æ ¹æ‹ ã¨ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚„å¼•ç”¨ã‚’å–ã‚Šå‡ºã™
# ç¤¾å†…ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚„ç ”ç©¶è«–æ–‡ã® Q&Aã€FAQ ãƒœãƒƒãƒˆã€RAG æ§‹ç¯‰
# ------------
# 2. FileSearch ã®æ©Ÿèƒ½
# ãƒ»ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢é€£æº: äº‹å‰ã« vector_store ã‚’ä½œæˆã—ã€files.upload() ã§æ–‡æ›¸ã‚’è¿½åŠ â†’è‡ªå‹•åŸ‹ã‚è¾¼ã¿ã€‚
# ãƒ»æ„å‘³æ¤œç´¢ + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: GPTâ€‘4o ãŒã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆâ†’ã‚¹ãƒˆã‚¢ã‚’æ¤œç´¢â†’æœ€é©ãªãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ã€‚
# ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«å¼•ç”¨: ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã« file_citation ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä»˜ä¸ã—ã€æ ¹æ‹ ç®‡æ‰€ã‚’ç¤ºã™ã€‚
# ãƒ»æ¤œç´¢çµæœå–å¾—: include=["file_search_call.results"] ã‚’æŒ‡å®šã™ã‚‹ã¨ã€
# ã€€æ¤œç´¢çµæœãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¹ã‚³ã‚¢ãƒ»æŠœç²‹ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’ JSON ã§å—ã‘å–ã‚Œã‚‹ã€‚
# ãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã«ä»˜ä¸ã—ãŸå±æ€§ï¼ˆä¾‹: {"type":"pdf"}ï¼‰ã§çµã‚Šè¾¼ã¿å¯èƒ½ã€‚
# --------------------------------------------------
def responses_01_061_filesearch(demo_name: str = "01_061_filesearch") -> None:
    init_messages(demo_name)
    model = select_model(demo_name)
    vector_store_id = 'vs_68345a403a548191817b3da8404e2d82'

    fs_tool = FileSearchToolParam(
        type="file_search",
        vector_store_ids=[vector_store_id],
        max_num_results=20
    )
    client = OpenAI()
    resp = client.responses.create(
        model=model,
        tools=[fs_tool],
        input="è«‹æ±‚æ›¸ã®æ”¯æ‰•ã„æœŸé™ã¯ï¼Ÿ",
        include=["file_search_call.results"]
    )
    st.write(resp.output_text)


# --------------------------------------------------
# WebSearch
# ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã®æœ€æ–°æƒ…å ±ã‚’å–å¾—ã—ã€ãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ‹¡å¼µã™ã‚‹
# ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç´„ã€æœ€æ–°çµ±è¨ˆã®å–å¾—ã€ç«¶åˆãƒªã‚µãƒ¼ãƒã€æ ªä¾¡ãƒ»ã‚¹ãƒãƒ¼ãƒ„é€Ÿå ±
# --------------------------------------------------
# 3. WebSearch ã®æ©Ÿèƒ½
# å¤–éƒ¨æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³: ãƒ¢ãƒ‡ãƒ«ãŒè£å´ã§ Bing / DuckDuckGo API ãªã©ã‚’ä½¿ç”¨ã—ã¦ã‚¯ã‚¨ãƒªã‚’ç™ºè¡Œã€‚
# æ¤œç´¢æ–‡è„ˆã‚µã‚¤ã‚º: search_context_sizeï¼ˆ"small" / "medium" / "large"ï¼‰ã§å–å¾—è¨˜äº‹æ•°ã¨æŠœç²‹é•·ã‚’èª¿æ•´ã€‚
# è¦ç´„ + å¼•ç”¨: ãƒ¢ãƒ‡ãƒ«ã¯å–å¾—ã—ãŸãƒšãƒ¼ã‚¸ã®è¦ç´„ã¨ URL å¼•ç”¨ã‚’å«ã‚ãŸå›ç­”ã‚’ç”Ÿæˆã€‚
# --------------------------------------------------
def responses_01_062_websearch(demo_name: str = "01_062_websearch") -> None:
    init_messages(demo_name)
    model = select_model(demo_name)

    user_location = UserLocation(
        type="approximate",
        country="JP",
        city="Tokyo",
        region="Tokyo"
    )

    ws_tool = WebSearchToolParam(
        type="web_search_preview",
        user_location=user_location,
        search_context_size="high"  # "low", "medium", ã¾ãŸã¯ "high"
    )

    client = OpenAI()
    # â˜… ãƒ¢ãƒ‡ãƒ«ã¯ gpt-4o ã¾ãŸã¯ gpt-4o-mini ã«ã—ã¦ãã ã•ã„
    response = client.responses.create(
        model=model,  # ã“ã“ã‚’ä¿®æ­£
        tools=[ws_tool],
        input="é€±æœ«ã®æ±äº¬ã®å¤©æ°—ã¨ãŠã™ã™ã‚ã®å±‹å†…ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã¯ï¼Ÿ"
    )
    st.write(response.output_text)

# --------------------------------------------------
# computer_use_tool_param
# --------------------------------------------------
def responses_01_07_computer_use_tool_param():
    client = OpenAI()

    # --è‡ªå‹•å®Ÿè¡Œã®æŒ‡ç¤º-------------------------------------------
    cu_tool = ComputerToolParam(
        type="computer_use_preview",  # fixed literal
        display_width=1280,
        display_height=800,
        environment="browser",  # "browser", "mac", "windows", or "ubuntu"
    )

    # å¿…é ˆ: EasyInputMessageParam ã‚’åˆ©ç”¨ã™ã‚‹ï¼ˆOpenAI API v1 ä»•æ§˜ï¼‰
    messages = [
        EasyInputMessageParam(
            role="user",
            content=[
                ResponseInputTextParam(
                    type="input_text",
                    text="ãƒ–ãƒ©ã‚¦ã‚¶ã§ https://news.ycombinator.com ã‚’é–‹ã„ã¦ã€ãƒˆãƒƒãƒ—è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ãƒ¡ãƒ¢å¸³ã«è²¼ã‚Šä»˜ã‘ã¦"
                )
            ]
        )
    ]

    response = client.responses.create(
        model="computer-use-preview",  # dedicated hostedâ€‘tool model
        tools=[cu_tool],
        input=messages,
        truncation="auto",  # MUST be "auto" for this model
        stream=False,  # optional
        include=["computer_call_output.output.image_url"]  # block name: ComputerUseã¯ã“ã‚Œ
    )
    import pprint
    pprint.pprint(response)
    # --------------------------------------------
    # è‡ªå‹•å®Ÿè¡Œ
    # --------------------------------------------
    for output in response.output:
        if hasattr(output, 'type') and output.type == 'computer_call':
            # ç”»åƒå–å¾—ã‚„æ“ä½œå†…å®¹è¡¨ç¤º
            if hasattr(output, 'action'):
                print('Action:', output.action)
            if hasattr(output, 'image_url'):
                print('Image URL:', output.image_url)


# responses_01_07_computer_use_tool_param()

# ==================================================
# ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³
# ==================================================
def main() -> None:
    init_page("core concept")

    page_funcs = {
        "01_00 responses.parseã®åŸºæœ¬"        : responses_parse_basic,
        "01_01  Responsesã‚µãƒ³ãƒ—ãƒ«(One Shot)" : responses_sample,
        "01_011 Responsesã‚µãƒ³ãƒ—ãƒ«(History)"   : responses_memory_sample,
        "01_02  ç”»åƒå…¥åŠ›(URL)"               : responses_01_02_passing_url,
        "01_021 ç”»åƒå…¥åŠ›(base64)"            : responses_01_021_base64_image,
        "01_03  æ§‹é€ åŒ–å‡ºåŠ›-responses"        : responses_01_03_structured_output,
        "01_031 æ§‹é€ åŒ–å‡ºåŠ›-parse"            : responses_01_031_structured_output,
        "01_04  é–¢æ•° calling"                : responses_01_04_function_calling,
        "01_05  ä¼šè©±çŠ¶æ…‹"                    : responses_01_05_conversation,
        "01_06  ãƒ„ãƒ¼ãƒ«:FileSearch, WebSearch": responses_01_06_tools_file_search,
        "01_061 File Search"                 : responses_01_061_filesearch,
        "01_062 Web Search"                  : responses_01_062_websearch,
        "01_07  Computer Use Tool Param"     : responses_01_07_computer_use_tool_param,
    }
    demo_name = st.sidebar.radio("ãƒ‡ãƒ¢ã‚’é¸æŠ", list(page_funcs.keys()))
    st.session_state.current_demo = demo_name
    page_funcs[demo_name](demo_name)


if __name__ == "__main__":
    main()

# streamlit run a20_01_responses_parse.py --server.port 8501
