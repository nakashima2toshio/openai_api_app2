# helper.py
# ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
# -----------------------------------------
import re
import time
import json
import logging
import yaml
from typing import List, Dict, Any, Optional, Union, Tuple, Literal, Callable
from pathlib import Path
from dataclasses import dataclass
from functools import wraps
from datetime import datetime
from abc import ABC, abstractmethod
import hashlib

import streamlit as st
import tiktoken
from openai import OpenAI

# -----------------------------------------------------
# "user": ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
# "assistant": AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‹ã‚‰ã®å¿œç­”
# "system": ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆChatCompletions APIã§ä½¿ç”¨ï¼‰
# "developer": é–‹ç™ºè€…ã«ã‚ˆã‚‹æŒ‡ç¤ºï¼ˆResponses APIã§ä½¿ç”¨ï¼‰
# -----------------------------------------------------
# [API] responses.createã®å ´åˆ Messages
# -----------------------------------------------------
from openai.types.responses import (
    EasyInputMessageParam,
    ResponseInputTextParam,
    ResponseInputImageParam,
    Response
)
# -----------------------------------------------------
# [API] chat.completions.create ã®å ´åˆã®input
# -----------------------------------------------------
from openai.types.chat import (
    ChatCompletionSystemMessageParam,
    ChatCompletionUserMessageParam,
    ChatCompletionAssistantMessageParam,
    ChatCompletionMessageParam,
)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --------------------------------------------------
# Case: For Software-Developer
# --------------------------------------------------
developer_text = (
    "You are a strong developer and good at teaching software developer professionals "
    "please provide an up-to-date, informed overview of the API by function, then show "
    "cookbook programs for each, and explain the API options."
    "ã‚ãªãŸã¯å¼·åŠ›ãªé–‹ç™ºè€…ã§ã‚ã‚Šã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºè€…ã®å°‚é–€å®¶ã«æ•™ãˆã‚‹ã®ãŒå¾—æ„ã§ã™ã€‚"
    "OpenAIã®APIã‚’æ©Ÿèƒ½åˆ¥ã«æœ€æ–°ã‹ã¤è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    "ãã‚Œãã‚Œã®APIã®ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç¤ºã—APIã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
)
user_text = (
    "Organize and identify the problem and list the issues. "
    "Then, provide a solution procedure for the issues you have organized and identified, "
    "and solve the problems/issues according to the solution procedures."
    "ä¸å…·åˆã€å•é¡Œã‚’ç‰¹å®šã—ã€æ•´ç†ã—ã¦ç®‡æ¡æ›¸ãã§åˆ—æŒ™ãƒ»èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    "æ¬¡ã«ã€æ•´ç†ãƒ»ç‰¹å®šã—ãŸå•é¡Œç‚¹ã®è§£æ±ºæ‰‹é †ã‚’ç¤ºã—ãªã•ã„ã€‚"
    "æ¬¡ã«ã€è§£æ±ºæ‰‹é †ã«å¾“ã£ã¦å•é¡Œãƒ»èª²é¡Œã‚’è§£æ±ºã—ã¦ãã ã•ã„ã€‚"
)
assistant_text = "OpenAIã®APIã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€å…¬å¼openaiãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¾¿åˆ©ã§ã™ã€‚å›ç­”ã¯æ—¥æœ¬èªã§"

# ==================================================
# è¨­å®šç®¡ç†
# ==================================================
class ConfigManager:
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç®¡ç†

    def __init__(self, config_path: str = "config.yaml"):
        self.config_path = Path(config_path)
        self._config = self._load_config()
        self._cache = {}

    def _load_config(self) -> Dict[str, Any]:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        if self.config_path.exists():
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)
            except Exception as e:
                logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
                return self._get_default_config()
        else:
            logger.warning(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.config_path}")
            return self._get_default_config()

    @staticmethod
    def _get_default_config(self) -> Dict[str, Any]:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        return {
            "models": {
                "default"  : "gpt-4o-mini",
                "available": ["gpt-4o-mini", "gpt-4o", "gpt-4.1", "gpt-4.1-mini"]
            },
            "api"   : {
                "timeout"    : 30,
                "max_retries": 3
            },
            "ui"    : {
                "page_title": "OpenAI API Demo",
                "layout"    : "wide"
            }
        }

    def get(self, key: str, default: Any = None) -> Any:
        # è¨­å®šå€¤ã®å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰
        if key in self._cache:
            return self._cache[key]

        keys = key.split('.')
        value = self._config
        for k in keys:
            if isinstance(value, dict):
                value = value.get(k)
            else:
                value = default
                break

        result = value if value is not None else default
        self._cache[key] = result
        return result

    def reload(self):
        # è¨­å®šã®å†èª­ã¿è¾¼ã¿
        self._config = self._load_config()
        self._cache.clear()


# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
config = ConfigManager()


# ==================================================
# ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿
# ==================================================
def error_handler(func):
    # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿

    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(f"Error in {func.__name__}: {str(e)}")
            error_msg = config.get("error_messages.general_error", f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            st.error(error_msg)
            if config.get("experimental.debug_mode", False):
                st.exception(e)
            return None

    return wrapper


def timer(func):
    # å®Ÿè¡Œæ™‚é–“è¨ˆæ¸¬ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿

    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        execution_time = end_time - start_time
        logger.info(f"{func.__name__} took {execution_time:.2f} seconds")

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãŒæœ‰åŠ¹ãªå ´åˆ
        if config.get("experimental.performance_monitoring", True):
            if 'performance_metrics' not in st.session_state:
                st.session_state.performance_metrics = []
            st.session_state.performance_metrics.append({
                'function'      : func.__name__,
                'execution_time': execution_time,
                'timestamp'     : datetime.now()
            })

        return result

    return wrapper


def cache_result(ttl: int = None):
    # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            if not config.get("cache.enabled", True):
                return func(*args, **kwargs)

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã®ç”Ÿæˆ
            cache_key = f"{func.__name__}_{hashlib.md5(str(args).encode() + str(kwargs).encode()).hexdigest()}"

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥é ˜åŸŸã‚’ç¢ºä¿
            if 'cache' not in st.session_state:
                st.session_state.cache = {}

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç¢ºèª
            if cache_key in st.session_state.cache:
                cached_data = st.session_state.cache[cache_key]
                if time.time() - cached_data['timestamp'] < (ttl or config.get("cache.ttl", 3600)):
                    return cached_data['result']

            # é–¢æ•°å®Ÿè¡Œã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
            result = func(*args, **kwargs)
            st.session_state.cache[cache_key] = {
                'result'   : result,
                'timestamp': time.time()
            }

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™
            max_size = config.get("cache.max_size", 100)
            if len(st.session_state.cache) > max_size:
                # æœ€ã‚‚å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
                oldest_key = min(st.session_state.cache, key=lambda k: st.session_state.cache[k]['timestamp'])
                del st.session_state.cache[oldest_key]

            return result

        return wrapper

    return decorator


# ==================================================
# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç®¡ç†
# chat.completions.crete --- "system", "user", "assistant"
# responses.create       --- "developer", "user", "assistant"
# ==================================================
# Roleå‹ã®å®šç¾©
RoleType = Literal["user", "assistant", "system", "developer"]


class MessageManager:
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®ç®¡ç†

    def __init__(self, session_key: str = "message_history"):
        self.session_key = session_key
        self._initialize_messages()

    def _initialize_messages(self):
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®åˆæœŸåŒ–
        if self.session_key not in st.session_state:
            st.session_state[self.session_key] = self.get_default_messages()

    @staticmethod
    def get_default_messages() -> List[EasyInputMessageParam]:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å–å¾—"
        messages = config.get("default_messages", {})
        return [
            EasyInputMessageParam(
                role="developer",
                content=messages.get("developer", "You are a helpful assistant.")
            ),
            EasyInputMessageParam(
                role="user",
                content=messages.get("user", "Hello.")
            ),
            EasyInputMessageParam(
                role="assistant",
                content=messages.get("assistant", "How can I help you today?")
            ),
        ]

    def add_message(self, role: RoleType, content: str):
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¿½åŠ 
        # å‹ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ 
        valid_roles: List[RoleType] = ["user", "assistant", "system", "developer"]
        if role not in valid_roles:
            raise ValueError(f"Invalid role: {role}. Must be one of {valid_roles}")

        st.session_state[self.session_key].append(
            EasyInputMessageParam(role=role, content=content)
        )

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°åˆ¶é™
        limit = config.get("ui.message_display_limit", 50)
        if len(st.session_state[self.session_key]) > limit:
            # æœ€åˆã®developerãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ä¿æŒ
            developer_msg = st.session_state[self.session_key][0] if st.session_state[self.session_key][0][
                                                                         'role'] == 'developer' else None
            st.session_state[self.session_key] = st.session_state[self.session_key][-limit:]
            if developer_msg and st.session_state[self.session_key][0]['role'] != 'developer':
                st.session_state[self.session_key].insert(0, developer_msg)

    def get_messages(self) -> List[EasyInputMessageParam]:
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®å–å¾—
        return st.session_state[self.session_key]

    def clear_messages(self):
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®ã‚¯ãƒªã‚¢
        st.session_state[self.session_key] = self.get_default_messages()

    def export_messages(self) -> Dict[str, Any]:
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        return {
            'messages'   : self.get_messages(),
            'exported_at': datetime.now().isoformat()
        }

    def import_messages(self, data: Dict[str, Any]):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        if 'messages' in data:
            st.session_state[self.session_key] = data['messages']


# ==================================================
# ãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†ï¼ˆæ‹¡å¼µç‰ˆï¼‰
# ==================================================
class TokenManager:
    """ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®ç®¡ç†ï¼ˆæ–°ãƒ¢ãƒ‡ãƒ«å¯¾å¿œï¼‰"""

    # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œè¡¨
    MODEL_ENCODINGS = {
        "gpt-4o"                   : "cl100k_base",
        "gpt-4o-mini"              : "cl100k_base",
        "gpt-4o-audio-preview"     : "cl100k_base",
        "gpt-4o-mini-audio-preview": "cl100k_base",
        "gpt-4.1"                  : "cl100k_base",
        "gpt-4.1-mini"             : "cl100k_base",
        "o1"                       : "cl100k_base",
        "o1-mini"                  : "cl100k_base",
        "o3"                       : "cl100k_base",
        "o3-mini"                  : "cl100k_base",
        "o4"                       : "cl100k_base",
        "o4-mini"                  : "cl100k_base",
    }

    @classmethod
    def count_tokens(cls, text: str, model: str = None) -> int:
        # ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        if model is None:
            model = config.get("models.default", "gpt-4o-mini")

        try:
            # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å–å¾—
            encoding_name = cls.MODEL_ENCODINGS.get(model, "cl100k_base")
            enc = tiktoken.get_encoding(encoding_name)
            return len(enc.encode(text))
        except Exception as e:
            logger.error(f"ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            # ç°¡æ˜“çš„ãªæ¨å®šï¼ˆ1æ–‡å­— = 0.5ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
            return len(text) // 2

    @classmethod
    def truncate_text(cls, text: str, max_tokens: int, model: str = None) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°ã«åˆ‡ã‚Šè©°ã‚"""
        if model is None:
            model = config.get("models.default", "gpt-4o-mini")

        try:
            encoding_name = cls.MODEL_ENCODINGS.get(model, "cl100k_base")
            enc = tiktoken.get_encoding(encoding_name)
            tokens = enc.encode(text)
            if len(tokens) <= max_tokens:
                return text
            return enc.decode(tokens[:max_tokens])
        except Exception as e:
            logger.error(f"ãƒ†ã‚­ã‚¹ãƒˆåˆ‡ã‚Šè©°ã‚ã‚¨ãƒ©ãƒ¼: {e}")
            # ç°¡æ˜“çš„ãªåˆ‡ã‚Šè©°ã‚
            estimated_chars = max_tokens * 2
            return text[:estimated_chars]

    @classmethod
    def estimate_cost(cls, input_tokens: int, output_tokens: int, model: str = None) -> float:
        """APIä½¿ç”¨ã‚³ã‚¹ãƒˆã®æ¨å®š"""
        if model is None:
            model = config.get("models.default", "gpt-4o-mini")

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–™é‡‘ã‚’å–å¾—
        pricing = config.get("model_pricing", {})
        model_pricing = pricing.get(model, pricing.get("gpt-4o-mini"))

        if not model_pricing:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ–™é‡‘
            model_pricing = {"input": 0.00015, "output": 0.0006}

        input_cost = (input_tokens / 1000) * model_pricing["input"]
        output_cost = (output_tokens / 1000) * model_pricing["output"]

        return input_cost + output_cost

    @classmethod
    def get_model_limits(cls, model: str) -> Dict[str, int]:
        """ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’å–å¾—"""
        limits = {
            "gpt-4o"      : {"max_tokens": 128000, "max_output": 4096},
            "gpt-4o-mini" : {"max_tokens": 128000, "max_output": 4096},
            "gpt-4.1"     : {"max_tokens": 128000, "max_output": 4096},
            "gpt-4.1-mini": {"max_tokens": 128000, "max_output": 4096},
            "o1"          : {"max_tokens": 128000, "max_output": 32768},
            "o1-mini"     : {"max_tokens": 128000, "max_output": 65536},
            "o3"          : {"max_tokens": 200000, "max_output": 100000},
            "o3-mini"     : {"max_tokens": 200000, "max_output": 100000},
            "o4"          : {"max_tokens": 256000, "max_output": 128000},
            "o4-mini"     : {"max_tokens": 256000, "max_output": 128000},
        }
        return limits.get(model, {"max_tokens": 128000, "max_output": 4096})


# ==================================================
# UI ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆæ‹¡å¼µç‰ˆï¼‰
# ==================================================
class UIHelper:
    # Streamlit UIç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆæ‹¡å¼µç‰ˆï¼‰

    @staticmethod
    def init_page(title: str = None, sidebar_title: str = None):
        # ãƒšãƒ¼ã‚¸ã®åˆæœŸåŒ–
        if title is None:
            title = config.get("ui.page_title", "OpenAI API Demo")
        if sidebar_title is None:
            sidebar_title = "ãƒ¡ãƒ‹ãƒ¥ãƒ¼"

        st.set_page_config(
            page_title=title,
            page_icon=config.get("ui.page_icon", "ğŸ¤–"),
            layout=config.get("ui.layout", "wide")
        )

        st.header(title)
        st.sidebar.title(sidebar_title)

    # -----------------------------------------------------------
    # select model:
    # -----------------------------------------------------------
    @staticmethod
    def select_model(key: str = "model_selection", category: str = None) -> str:
        # ãƒ¢ãƒ‡ãƒ«é¸æŠUIï¼ˆã‚«ãƒ†ã‚´ãƒªå¯¾å¿œï¼‰
        models = config.get("models.available", ["gpt-4o", "gpt-4o-mini"])
        default_model = config.get("models.default", "gpt-4o-mini")

        # ã‚«ãƒ†ã‚´ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if category:
            if category == "reasoning":
                models = [m for m in models if m.startswith("o")]
            elif category == "standard":
                models = [m for m in models if m.startswith("gpt")]
            elif category == "audio":
                models = [m for m in models if "audio" in m]

        default_index = models.index(default_model) if default_model in models else 0

        selected = st.sidebar.selectbox(
            "ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
            models,
            index=default_index,
            key=key
        )

        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®è¡¨ç¤º
        with st.sidebar.expander("ãƒ¢ãƒ‡ãƒ«æƒ…å ±"):
            limits = TokenManager.get_model_limits(selected)
            st.write(f"æœ€å¤§å…¥åŠ›: {limits['max_tokens']:,} tokens")
            st.write(f"æœ€å¤§å‡ºåŠ›: {limits['max_output']:,} tokens")

        return selected

    # -----------------------------------------------------------
    # select speech model (Text-to-Speech):
    # -----------------------------------------------------------
    @staticmethod
    def select_speech_model(key: str = "speech_model_selection", category: str = None) -> str:
        # éŸ³å£°åˆæˆãƒ¢ãƒ‡ãƒ«é¸æŠUIï¼ˆã‚«ãƒ†ã‚´ãƒªå¯¾å¿œï¼‰
        # éŸ³å£°åˆæˆç”¨ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ
        all_speech_models = [
            "tts-1", "tts-1-hd",  # å°‚ç”¨TTS
            "gpt-4o-audio-preview", "gpt-4o-mini-audio-preview",  # éŸ³å£°å¯¾è©±
            "o3-mini", "o4-mini", "o1-mini"  # æ¨è«–ç³»ï¼ˆéŸ³å£°å¯¾å¿œï¼‰
        ]

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«
        default_speech_model = "tts-1"

        # ã‚«ãƒ†ã‚´ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if category:
            if category == "tts":
                models = [m for m in all_speech_models if m.startswith("tts")]
            elif category == "audio_chat":
                models = [m for m in all_speech_models if "audio" in m]
            elif category == "reasoning":
                models = [m for m in all_speech_models if m.startswith("o")]
            else:
                models = all_speech_models
        else:
            models = all_speech_models

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è¨­å®š
        default_index = models.index(default_speech_model) if default_speech_model in models else 0

        selected = st.sidebar.selectbox(
            "éŸ³å£°åˆæˆãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
            models,
            index=default_index,
            key=key
        )

        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®è¡¨ç¤º
        with st.sidebar.expander("éŸ³å£°ãƒ¢ãƒ‡ãƒ«æƒ…å ±"):
            if selected.startswith("tts"):
                st.write("**TTSå°‚ç”¨ãƒ¢ãƒ‡ãƒ«**")
                if selected == "tts-1":
                    st.write("- é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆ")
                    st.write("- éŸ³è³ª: æ¨™æº–")
                elif selected == "tts-1-hd":
                    st.write("- é«˜éŸ³è³ªãƒ»ä½é…å»¶")
                    st.write("- éŸ³è³ª: é«˜å“è³ª")
            elif "audio" in selected:
                st.write("**éŸ³å£°å¯¾è©±ãƒ¢ãƒ‡ãƒ«**")
                st.write("- ãƒ†ã‚­ã‚¹ãƒˆ+éŸ³å£°å…¥å‡ºåŠ›å¯¾å¿œ")
                st.write("- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾è©±å¯èƒ½")
                # OpenAI APIã®åˆ¶é™æƒ…å ±ãŒã‚ã‚Œã°è¡¨ç¤º
                limits = TokenManager.get_model_limits(selected)
                st.write(f"æœ€å¤§å…¥åŠ›: {limits['max_tokens']:,} tokens")
                st.write(f"æœ€å¤§å‡ºåŠ›: {limits['max_output']:,} tokens")
            elif selected.startswith("o"):
                st.write("**æ¨è«–ç³»ãƒ¢ãƒ‡ãƒ«ï¼ˆéŸ³å£°å¯¾å¿œï¼‰**")
                st.write("- é«˜åº¦ãªæ¨è«–èƒ½åŠ›")
                st.write("- è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å¯¾å¿œ")
                limits = TokenManager.get_model_limits(selected)
                st.write(f"æœ€å¤§å…¥åŠ›: {limits['max_tokens']:,} tokens")
                st.write(f"æœ€å¤§å‡ºåŠ›: {limits['max_output']:,} tokens")

        return selected

    # -----------------------------------------------------------
    # select whisper model (Speech-to-Text):
    # -----------------------------------------------------------
    @staticmethod
    def select_whisper_model(key: str = "whisper_model_selection", category: str = None) -> str:
        # éŸ³å£°èªè­˜/ç¿»è¨³ãƒ¢ãƒ‡ãƒ«é¸æŠUIï¼ˆã‚«ãƒ†ã‚´ãƒªå¯¾å¿œï¼‰
        # éŸ³å£°èªè­˜/ç¿»è¨³ç”¨ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ
        all_whisper_models = [
            "whisper-1",  # å°‚ç”¨STT
            "gpt-4o-transcribe", "gpt-4o-mini-transcribe",  # GPTç³»STT
            "gpt-4o-audio-preview", "gpt-4o-mini-audio-preview"  # éŸ³å£°å¯¾è©±ï¼ˆSTTæ©Ÿèƒ½å«ã‚€ï¼‰
        ]

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«
        default_whisper_model = "whisper-1"

        # ã‚«ãƒ†ã‚´ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if category:
            if category == "whisper":
                models = [m for m in all_whisper_models if "whisper" in m]
            elif category == "transcribe":
                models = [m for m in all_whisper_models if "transcribe" in m]
            elif category == "audio_chat":
                models = [m for m in all_whisper_models if "audio-preview" in m]
            elif category == "gpt":
                models = [m for m in all_whisper_models if m.startswith("gpt")]
            else:
                models = all_whisper_models
        else:
            models = all_whisper_models

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è¨­å®š
        default_index = models.index(default_whisper_model) if default_whisper_model in models else 0

        selected = st.sidebar.selectbox(
            "éŸ³å£°èªè­˜/ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
            models,
            index=default_index,
            key=key
        )

        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®è¡¨ç¤º
        with st.sidebar.expander("éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«æƒ…å ±"):
            if selected == "whisper-1":
                st.write("**Whisperå°‚ç”¨ãƒ¢ãƒ‡ãƒ«**")
                st.write("- å¤šè¨€èªå¯¾å¿œ")
                st.write("- è»¢å†™ãƒ»ç¿»è¨³å¯¾å¿œ")
                st.write("- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: æœ€å¤§25MB")
                st.write("- å¯¾å¿œå½¢å¼: mp3, mp4, wav, webm, m4a, flac, etc.")
            elif "transcribe" in selected:
                st.write("**GPTç³»è»¢å†™ãƒ¢ãƒ‡ãƒ«**")
                st.write("- é«˜ç²¾åº¦è»¢å†™")
                st.write("- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç†è§£")
                if "mini" in selected:
                    st.write("- é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆç‰ˆ")
                else:
                    st.write("- é«˜æ€§èƒ½ç‰ˆ")
            elif "audio-preview" in selected:
                st.write("**éŸ³å£°å¯¾è©±ãƒ¢ãƒ‡ãƒ«ï¼ˆSTTæ©Ÿèƒ½ï¼‰**")
                st.write("- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†")
                st.write("- ãƒ†ã‚­ã‚¹ãƒˆ+éŸ³å£°å…¥å‡ºåŠ›")
                limits = TokenManager.get_model_limits(selected)
                st.write(f"æœ€å¤§å…¥åŠ›: {limits['max_tokens']:,} tokens")
                st.write(f"æœ€å¤§å‡ºåŠ›: {limits['max_output']:,} tokens")

            # å…±é€šæƒ…å ±
            st.write("---")
            st.write("**å¯¾å¿œè¨€èª**: æ—¥æœ¬èªã€è‹±èªã€ãã®ä»–å¤šæ•°")

            # ã‚³ã‚¹ãƒˆæƒ…å ±ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ã§ãã‚‹å ´åˆï¼‰
            pricing = config.get("model_pricing", {}).get(selected)
            if pricing:
                st.write("**æ–™é‡‘æƒ…å ±**:")
                if "input" in pricing:
                    st.write(f"- å…¥åŠ›: ${pricing['input']}/1K tokens")
                if "output" in pricing:
                    st.write(f"- å‡ºåŠ›: ${pricing['output']}/1K tokens")

        return selected

    # -----------------------------------------------------------
    @staticmethod
    def create_form(key: str, submit_label: str = "é€ä¿¡") -> Tuple[Any, bool]:
        """ãƒ•ã‚©ãƒ¼ãƒ ã®ä½œæˆ"""
        form = st.form(key=key)
        submitted = form.form_submit_button(submit_label)
        return form, submitted

    @staticmethod
    def display_messages(messages: List[EasyInputMessageParam], show_system: bool = False):
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®è¡¨ç¤ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        for i, msg in enumerate(messages):
            role = msg.get("role", "")
            content = msg.get("content", "")

            if role == "user":
                with st.chat_message("user"):
                    if isinstance(content, list):
                        # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å‡¦ç†
                        for item in content:
                            if item.get("type") == "input_text":
                                st.markdown(item.get("text", ""))
                            elif item.get("type") == "input_image":
                                st.image(item.get("image_url", ""))
                    else:
                        st.markdown(content)
            elif role == "assistant":
                with st.chat_message("assistant"):
                    st.markdown(content)
            elif (role == "developer" or role == "system") and show_system:
                with st.expander(f"{role.capitalize()} Message", expanded=False):
                    st.markdown(f"*{content}*")

    @staticmethod
    def show_token_info(text: str, model: str = None):
        """ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã®è¡¨ç¤ºï¼ˆæ‹¡å¼µç‰ˆï¼‰"""
        token_count = TokenManager.count_tokens(text, model)
        limits = TokenManager.get_model_limits(model)

        col1, col2 = st.sidebar.columns(2)
        with col1:
            st.metric("ãƒˆãƒ¼ã‚¯ãƒ³æ•°", f"{token_count:,}")
        with col2:
            usage_percent = (token_count / limits['max_tokens']) * 100
            st.metric("ä½¿ç”¨ç‡", f"{usage_percent:.1f}%")

        # ã‚³ã‚¹ãƒˆæ¨å®šï¼ˆä»®å®š: å‡ºåŠ›ã¯å…¥åŠ›ã®50%ï¼‰
        estimated_output = token_count // 2
        cost = TokenManager.estimate_cost(token_count, estimated_output, model)
        st.sidebar.metric("æ¨å®šã‚³ã‚¹ãƒˆ", f"${cost:.4f}")

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        st.sidebar.progress(min(usage_percent / 100, 1.0))

    @staticmethod
    def create_tabs(tab_names: List[str], key: str = "tabs") -> List[Any]:
        # ã‚¿ãƒ–ã®ä½œæˆ
        return st.tabs(tab_names)

    @staticmethod
    def create_columns(spec: List[Union[int, float]], gap: str = "medium") -> List[Any]:
        # ã‚«ãƒ©ãƒ ã®ä½œæˆ
        return st.columns(spec, gap=gap)

    @staticmethod
    def show_metrics(metrics: Dict[str, Any], columns: int = 3):
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º
        cols = st.columns(columns)
        for i, (label, value) in enumerate(metrics.items()):
            with cols[i % columns]:
                if isinstance(value, dict):
                    st.metric(label, value.get('value'), value.get('delta'))
                else:
                    st.metric(label, value)

    @staticmethod
    def create_download_button(data: Any, filename: str, mime_type: str = "text/plain", label: str = "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®ä½œæˆ
        if isinstance(data, dict):
            data = json.dumps(data, ensure_ascii=False, indent=2)
        elif isinstance(data, list):
            data = json.dumps(data, ensure_ascii=False, indent=2)

        st.download_button(
            label=label,
            data=data,
            file_name=filename,
            mime=mime_type
        )


# ==================================================
# ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
# ==================================================
class ResponseProcessor:
    # API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç†

    @staticmethod
    def extract_text(response: Response) -> List[str]:
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        texts = []

        if hasattr(response, 'output'):
            for item in response.output:
                if hasattr(item, 'type') and item.type == "message":
                    if hasattr(item, 'content'):
                        for content in item.content:
                            if hasattr(content, 'type') and content.type == "output_text":
                                if hasattr(content, 'text'):
                                    texts.append(content.text)

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: output_textå±æ€§
        if not texts and hasattr(response, 'output_text'):
            texts.append(response.output_text)

        return texts

    @staticmethod
    def format_response(response: Response) -> Dict[str, Any]:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ•´å½¢"""
        return {
            "id"        : getattr(response, "id", None),
            "model"     : getattr(response, "model", None),
            "created_at": getattr(response, "created_at", None),
            "text"      : ResponseProcessor.extract_text(response),
            "usage"     : getattr(response, "usage", {}),
        }

    @staticmethod
    def display_response(response: Response, show_details: bool = True):
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è¡¨ç¤ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        texts = ResponseProcessor.extract_text(response)

        if texts:
            for i, text in enumerate(texts, 1):
                if len(texts) > 1:
                    st.subheader(f"å›ç­” {i}")
                st.write(text)
        else:
            st.warning("ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        # è©³ç´°æƒ…å ±ã®è¡¨ç¤º
        if show_details:
            with st.expander("è©³ç´°æƒ…å ±"):
                formatted = ResponseProcessor.format_response(response)

                # ä½¿ç”¨çŠ¶æ³ã®è¡¨ç¤º
                if 'usage' in formatted and formatted['usage']:
                    usage = formatted['usage']
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³", usage.get('prompt_tokens', 0))
                    with col2:
                        st.metric("å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³", usage.get('completion_tokens', 0))
                    with col3:
                        st.metric("åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³", usage.get('total_tokens', 0))

                # JSONå½¢å¼ã§ã®è¡¨ç¤º
                st.json(formatted)

    @staticmethod
    def save_response(response: Response, filename: str = None) -> str:
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ä¿å­˜
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"response_{timestamp}.json"

        formatted = ResponseProcessor.format_response(response)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç”Ÿæˆ
        logs_dir = Path(config.get("paths.logs_dir", "logs"))
        logs_dir.mkdir(exist_ok=True)
        filepath = logs_dir / filename

        # ä¿å­˜
        save_json_file(formatted, str(filepath))

        return str(filepath)


# ==================================================
# åŸºåº•ã‚¯ãƒ©ã‚¹
# ==================================================
class DemoBase(ABC):
    # ãƒ‡ãƒ¢ã®åŸºåº•ã‚¯ãƒ©ã‚¹

    def __init__(self, demo_name: str, title: str = None):
        self.demo_name = demo_name
        self.title = title or demo_name
        self.key_prefix = sanitize_key(demo_name)
        self.message_manager = MessageManager(f"messages_{self.key_prefix}")

    @abstractmethod
    def run(self):
        # ãƒ‡ãƒ¢ã®å®Ÿè¡Œï¼ˆã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰
        pass

    def setup_ui(self):
        # å…±é€šUIè¨­å®š
        st.subheader(self.title)

        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        self.model = UIHelper.select_model(f"model_{self.key_prefix}")

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã®ã‚¯ãƒªã‚¢
        if st.sidebar.button("å±¥æ­´ã‚¯ãƒªã‚¢", key=f"clear_{self.key_prefix}"):
            self.message_manager.clear_messages()
            st.rerun()

    def display_messages(self):
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
        messages = self.message_manager.get_messages()
        UIHelper.display_messages(messages)

    def add_user_message(self, content: str):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¿½åŠ 
        self.message_manager.add_message("user", content)

    def add_assistant_message(self, content: str):
        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¿½åŠ 
        self.message_manager.add_message("assistant", content)

    @error_handler
    @timer
    def call_api(self, messages: List[EasyInputMessageParam], **kwargs) -> Response:
        # APIå‘¼ã³å‡ºã—ï¼ˆå…±é€šå‡¦ç†ï¼‰
        client = OpenAI()

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        params = {
            "model"     : self.model,
            "input"  : messages,
            # "max_tokens": config.get("api.max_tokens", 4096),
        }
        params.update(kwargs)

        # APIå‘¼ã³å‡ºã—
        response = client.responses.create(**params)

        return response


# ==================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ==================================================
def sanitize_key(name: str) -> str:
    # Streamlit keyç”¨ã«å®‰å…¨ãªæ–‡å­—åˆ—ã¸å¤‰æ›
    return re.sub(r'[^0-9a-zA-Z_]', '_', name).lower()


def load_json_file(filepath: str) -> Optional[Dict[str, Any]]:
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def save_json_file(data: Dict[str, Any], filepath: str) -> bool:
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜
    try:
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        Path(filepath).parent.mkdir(parents=True, exist_ok=True)

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        logger.error(f"JSONãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def format_timestamp(timestamp: Union[int, float, str] = None) -> str:
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    if timestamp is None:
        timestamp = time.time()

    if isinstance(timestamp, str):
        return timestamp

    return datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")


def create_session_id() -> str:
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ç”Ÿæˆ
    return hashlib.md5(f"{time.time()}_{id(st)}".encode()).hexdigest()[:8]


# ==================================================
# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°
# ==================================================
def init_page(title: str):
    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°
    UIHelper.init_page(title)


def init_messages(demo_name: str = ""):
    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°
    manager = MessageManager(f"messages_{sanitize_key(demo_name)}")

    if st.sidebar.button("ä¼šè©±å±¥æ­´ã®ã‚¯ãƒªã‚¢", key=f"clear_{sanitize_key(demo_name)}"):
        manager.clear_messages()


def select_model(demo_name: str = "") -> str:
    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°
    return UIHelper.select_model(f"model_{sanitize_key(demo_name)}")


def get_default_messages() -> List[EasyInputMessageParam]:
    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°
    manager = MessageManager()
    return manager.get_default_messages()


def extract_text_from_response(response: Response) -> List[str]:
    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°
    return ResponseProcessor.extract_text(response)


def append_user_message(append_text: str, image_url: Optional[str] = None) -> List[EasyInputMessageParam]:
    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°
    messages = get_default_messages()
    if image_url:
        content = [
            ResponseInputTextParam(type="input_text", text=append_text),
            ResponseInputImageParam(type="input_image", image_url=image_url, detail="auto")
        ]
        messages.append(EasyInputMessageParam(role="user", content=content))
    else:
        messages.append(EasyInputMessageParam(role="user", content=append_text))
    return messages


# ==================================================
# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# ==================================================
__all__ = [
    # ã‚¯ãƒ©ã‚¹
    'ConfigManager',
    'MessageManager',
    'TokenManager',
    'UIHelper',
    'ResponseProcessor',
    'DemoBase',

    # å‹å®šç¾©
    'RoleType',

    # ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿
    'error_handler',
    'timer',
    'cache_result',

    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    'sanitize_key',
    'load_json_file',
    'save_json_file',
    'format_timestamp',
    'create_session_id',

    # å¾Œæ–¹äº’æ›æ€§
    'init_page',
    'init_messages',
    'select_model',
    'get_default_messages',
    'extract_text_from_response',
    'append_user_message',
]
